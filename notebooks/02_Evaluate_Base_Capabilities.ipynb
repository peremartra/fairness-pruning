{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/peremartra/fairness-pruning/blob/main/notebooks/02_Evaluate_Base_Capabilities.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzfjNg_SIvXD"
      },
      "source": [
        "# Fairness Pruning Research - Base Model Evaluation\n",
        "## 02 - Comprehensive Benchmark Suite for Unpruned Models\n",
        "\n",
        "### Establishing Performance Baselines for Bias Mitigation Research\n",
        "by [Pere Martra](https://github.com/peremartra)\n",
        "\n",
        "[![GitHub](https://img.shields.io/badge/‚≠ê_Star-OptiPFair-orange?logo=github&logoColor=white)](https://github.com/peremartra/optipfair)\n",
        "[![PyPI](https://img.shields.io/pypi/v/optipfair?logo=python&logoColor=white&label=v)](https://pypi.org/project/optipfair/)\n",
        "\n",
        "**Repository:** [github.com/peremartra/fairness-pruning](https://github.com/peremartra/fairness-pruning)\n",
        "\n",
        "---\n",
        "\n",
        "**Colab Environment:** GPU L4 or A100\n",
        "\n",
        "**Models to Evaluate:**\n",
        "* Llama-3.2-1B (base)\n",
        "* Llama-3.2-3B (base)\n",
        "* Additional models defined in `EXPERIMENT_CONFIG`\n",
        "\n",
        "**Benchmarks (15 total):**\n",
        "* English: MMLU, HellaSwag, BoolQ, ARC-Challenge, WinoGrande, PIQA, TruthfulQA, GSM8K, IFEval, MUSR\n",
        "* Spanish: Belebele, XCOPA, MMLU-ES\n",
        "* Language Modeling: WikiText, Lambada-OpenAI\n",
        "\n",
        "**Estimated Runtime:** ~3-4 hours (varies by number of models)\n",
        "\n",
        "---\n",
        "\n",
        "## üìã Objective\n",
        "\n",
        "Establish **performance baselines** for the Fairness Pruning project by evaluating unpruned base models.\n",
        "\n",
        "**Purpose:**\n",
        "1. Measure baseline performance before bias mitigation interventions\n",
        "2. Create reference metrics for future pruned model comparisons\n",
        "3. Validate benchmark configurations across different architectures\n",
        "4. Capture cross-lingual performance (English + Spanish)\n",
        "\n",
        "**Features:**\n",
        "- ‚úÖ Checkpoint/Resume Support (survives Colab disconnections)\n",
        "- ‚úÖ Multi-Model Support (generic, not 1B-specific)\n",
        "- ‚úÖ Robust Error Handling (continues on task failures)\n",
        "- ‚úÖ Automated Path Management (no manual configuration needed)\n",
        "\n",
        "**Note:** This notebook evaluates ONLY base models (no pruning applied). For bias mitigation experiments with pruned models, see subsequent notebooks.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkVFbeCMIvXF"
      },
      "source": [
        "# 1. Setup & Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nAo67s0lIvXF",
        "outputId": "9f28f47a-a258-4dff-94d9-311bda2e3976",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m52.2/52.2 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m53.8/53.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m95.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m293.6/293.6 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m91.1/91.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Install required libraries\n",
        "!pip install -q optipfair\n",
        "!pip install -q lm-eval\n",
        "!pip install -q langdetect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWIHQuIGIvXG",
        "outputId": "e9680e68-a45d-49b7-e7c7-8768a4ba028e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive for checkpoint persistence\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DG2nO7YpIvXG",
        "outputId": "4b3d4595-89fd-499c-aec6-0ba07e45b9eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ utils.py downloaded successfully\n"
          ]
        }
      ],
      "source": [
        "# Download utils.py from GitHub repository\n",
        "!wget -q https://raw.githubusercontent.com/peremartra/fairness-pruning/main/utils.py\n",
        "\n",
        "# Verify download\n",
        "import os\n",
        "if os.path.exists('utils.py'):\n",
        "    print(\"‚úÖ utils.py downloaded successfully\")\n",
        "else:\n",
        "    print(\"‚ùå Failed to download utils.py\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://raw.githubusercontent.com/peremartra/fairness-pruning/main/veritas_qa_ca.yaml\n",
        "!wget -q https://raw.githubusercontent.com/peremartra/fairness-pruning/main/veritas_qa_es.yaml"
      ],
      "metadata": {
        "id": "gQKRdEHcSFYK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import lm_eval\n",
        "\n",
        "print(f\"{'='*50}\")\n",
        "print(\"üì¶ INSTALLING VERITAS QA (ES/CA)\")\n",
        "print(f\"{'='*50}\")\n",
        "\n",
        "lib_path = os.path.dirname(lm_eval.__file__)\n",
        "target_dir = os.path.join(lib_path, \"tasks\", \"veritas_qa\")\n",
        "\n",
        "os.makedirs(target_dir, exist_ok=True)\n",
        "print(f\"üìç TASKS DIRECTORY: {target_dir}\")\n",
        "\n",
        "for lang in [\"es\", \"ca\"]:\n",
        "    filename = f\"veritas_qa_{lang}.yaml\"\n",
        "\n",
        "    if os.path.exists(filename):\n",
        "        dst = os.path.join(target_dir, filename)\n",
        "        shutil.move(filename, dst)\n",
        "        print(f\"   ‚úÖ {filename} -> Installation OK\")\n",
        "    else:\n",
        "        print(f\"   ‚ùå Error: {filename} no downloaded.\")\n",
        "\n",
        "print(\"\\nüöÄ OK!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SsrTGtkwAh45",
        "outputId": "9ab6062e-e612-4736-97d4-02857648ca5d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "üì¶ INSTALLING VERITAS QA (ES/CA)\n",
            "==================================================\n",
            "üìç TASKS DIRECTORY: /usr/local/lib/python3.12/dist-packages/lm_eval/tasks/veritas_qa\n",
            "   ‚úÖ veritas_qa_es.yaml -> Installation OK\n",
            "   ‚úÖ veritas_qa_ca.yaml -> Installation OK\n",
            "\n",
            "üöÄ OK!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHjkx6_QIvXG",
        "outputId": "c8a38e6a-3d69-4698-a8b3-9baa8ecb5998"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ All imports successful\n",
            "üì± Device: GPU\n",
            "   GPU: NVIDIA L4\n",
            "   Memory: 23.8 GB\n"
          ]
        }
      ],
      "source": [
        "# Import core libraries and utilities\n",
        "import torch\n",
        "import json\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "import logging\n",
        "\n",
        "# Import our utility functions\n",
        "from utils import (\n",
        "    EXPERIMENT_CONFIG,\n",
        "    BENCHMARKS_BASE,\n",
        "    load_or_create_model,\n",
        "    run_robust_evaluation,\n",
        "    clear_gpu_cache,\n",
        "    get_model_stats,\n",
        "    format_results_table\n",
        ")\n",
        "\n",
        "logging.getLogger(\"lm_eval\").setLevel(logging.INFO)\n",
        "\n",
        "print(\"‚úÖ All imports successful\")\n",
        "print(f\"üì± Device: {'GPU' if torch.cuda.is_available() else 'CPU'}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Helper Functions\n",
        "\n",
        "Utility functions for automatic checkpoint path generation and model size detection."
      ],
      "metadata": {
        "id": "GSOqtWXbhrRf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import os\n",
        "\n",
        "def get_model_size(model_name: str) -> str:\n",
        "    \"\"\"Extract model size identifier from HuggingFace model name.\n",
        "\n",
        "    Examples:\n",
        "        \"meta-llama/Llama-3.2-1B\" ‚Üí \"1b\"\n",
        "        \"meta-llama/Llama-3.2-3B-Instruct\" ‚Üí \"3b_instruct\"\n",
        "        \"BSC-LT/salamandra-2b\" ‚Üí \"2b\"\n",
        "    \"\"\"\n",
        "    match = re.search(r'(\\d+\\.?\\d*)[Bb]', model_name)\n",
        "    if not match:\n",
        "        return \"unknown\"\n",
        "\n",
        "    size = match.group(1).replace('.', '_') + \"b\"\n",
        "    if \"instruct\" in model_name.lower():\n",
        "        size += \"_instruct\"\n",
        "\n",
        "    return size.lower()\n",
        "\n",
        "def get_checkpoint_path(model_name: str, base_dir: str) -> str:\n",
        "    \"\"\"Generate checkpoint path with size-based subdirectory.\n",
        "\n",
        "    Args:\n",
        "        model_name: Full HuggingFace model identifier\n",
        "        base_dir: Base directory for checkpoints\n",
        "\n",
        "    Returns:\n",
        "        Full path to checkpoint file\n",
        "    \"\"\"\n",
        "    model_size = get_model_size(model_name)\n",
        "    safe_name = model_name.replace('/', '_').replace('-', '_').lower()\n",
        "    checkpoint_dir = os.path.join(base_dir, model_size)\n",
        "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "    return os.path.join(checkpoint_dir, f\"{safe_name}.json\")\n",
        "\n",
        "# Test with EXPERIMENT_CONFIG\n",
        "print(\"Testing helper functions with EXPERIMENT_CONFIG:\")\n",
        "print(\"-\" * 70)\n",
        "for cfg in EXPERIMENT_CONFIG:\n",
        "    model_id = cfg['base_model']\n",
        "    size = get_model_size(model_id)\n",
        "    print(f\"{model_id:<50} ‚Üí {size}\")\n",
        "print(\"-\" * 70)"
      ],
      "metadata": {
        "id": "Vb0Sq8eqhrRg",
        "outputId": "98238991-e4b5-48ac-ded1-1b269a2f4b3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing helper functions with EXPERIMENT_CONFIG:\n",
            "----------------------------------------------------------------------\n",
            "BSC-LT/salamandra-2b                               ‚Üí 2b\n",
            "meta-llama/Llama-3.2-1B                            ‚Üí 1b\n",
            "meta-llama/Llama-3.2-3B                            ‚Üí 3b\n",
            "----------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Configuration & Evaluation Plan\n",
        "\n",
        "This section prepares the evaluation for all models defined in `EXPERIMENT_CONFIG`."
      ],
      "metadata": {
        "id": "AI3mbbDchrRg"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LixoDuXJIvXG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88fc8917-0a22-4ee1-9369-1432c1823256"
      },
      "source": [
        "# Directory setup\n",
        "CHECKPOINT_BASE_DIR = \"/content/drive/MyDrive/fair_pruning/checkpoints\"\n",
        "RESULTS_DIR = \"/content/drive/MyDrive/fair_pruning/results\"\n",
        "Path(RESULTS_DIR).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# De-duplicate models from EXPERIMENT_CONFIG\n",
        "unique_models = list(dict.fromkeys([cfg[\"base_model\"] for cfg in EXPERIMENT_CONFIG]))\n",
        "\n",
        "print(f\"{'='*70}\")\n",
        "print(\"üìä EVALUATION PLAN: Base Model Benchmarking\")\n",
        "print(f\"{'='*70}\\n\")\n",
        "print(f\"Models to evaluate: {len(unique_models)}\")\n",
        "print(f\"Benchmarks per model: {len(BENCHMARKS_BASE)}\")\n",
        "print(f\"Total evaluations: {len(unique_models) * len(BENCHMARKS_BASE)}\")\n",
        "print(f\"Estimated time: ~{len(unique_models) * 1.5:.1f} hours\\n\")\n",
        "\n",
        "# Display models with checkpoint status\n",
        "print(\"Models to evaluate:\")\n",
        "print(\"-\" * 70)\n",
        "print(f\"{'Model ID':<50} {'Size':<10} {'Status'}\")\n",
        "print(\"-\" * 70)\n",
        "for model_id in unique_models:\n",
        "    size = get_model_size(model_id)\n",
        "    cp_path = get_checkpoint_path(model_id, CHECKPOINT_BASE_DIR)\n",
        "    exists = \"‚úÖ Exists\" if Path(cp_path).exists() else \"üÜï New\"\n",
        "    print(f\"{model_id:<50} {size:<10} {exists}\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "# Display benchmarks\n",
        "print(\"\\nBenchmarks:\")\n",
        "print(\"-\" * 70)\n",
        "for i, task in enumerate(BENCHMARKS_BASE, 1):\n",
        "    fewshot_str = f\"{task['num_fewshot']}-shot\"\n",
        "    print(f\"{i:2d}. {task['name']:<30} {fewshot_str}\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "print(f\"\\n‚öôÔ∏è  Configuration:\")\n",
        "print(f\"   - Checkpointing: Enabled (per-task granularity)\")\n",
        "print(f\"   - Auto-resume: Yes (survives disconnections)\")\n",
        "print(f\"   - Error handling: Skip failed tasks, continue evaluation\")\n",
        "print(f\"   - Device: {'GPU' if torch.cuda.is_available() else 'CPU'}\\n\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "üìä EVALUATION PLAN: Base Model Benchmarking\n",
            "======================================================================\n",
            "\n",
            "Models to evaluate: 3\n",
            "Benchmarks per model: 14\n",
            "Total evaluations: 42\n",
            "Estimated time: ~4.5 hours\n",
            "\n",
            "Models to evaluate:\n",
            "----------------------------------------------------------------------\n",
            "Model ID                                           Size       Status\n",
            "----------------------------------------------------------------------\n",
            "BSC-LT/salamandra-2b                               2b         ‚úÖ Exists\n",
            "meta-llama/Llama-3.2-1B                            1b         ‚úÖ Exists\n",
            "meta-llama/Llama-3.2-3B                            3b         ‚úÖ Exists\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Benchmarks:\n",
            "----------------------------------------------------------------------\n",
            " 1. wikitext                       0-shot\n",
            " 2. lambada_openai                 0-shot\n",
            " 3. ifeval                         0-shot\n",
            " 4. gsm8k                          5-shot\n",
            " 5. mmlu                           5-shot\n",
            " 6. arc_challenge                  0-shot\n",
            " 7. hellaswag                      0-shot\n",
            " 8. truthfulqa_mc2                 0-shot\n",
            " 9. global_mmlu_es                 5-shot\n",
            "10. arc_es                         0-shot\n",
            "11. hellaswag_es                   0-shot\n",
            "12. belebele_spa_Latn              0-shot\n",
            "13. veritas_qa_es                  0-shot\n",
            "14. veritas_qa_ca                  0-shot\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "‚öôÔ∏è  Configuration:\n",
            "   - Checkpointing: Enabled (per-task granularity)\n",
            "   - Auto-resume: Yes (survives disconnections)\n",
            "   - Error handling: Skip failed tasks, continue evaluation\n",
            "   - Device: GPU\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7U0stRUIvXG",
        "outputId": "b731cf61-e051-448a-d2fd-e3dcb0e00b69"
      },
      "source": [
        "# 3. Base Model Evaluation\n",
        "\n",
        "Evaluates each base model across all benchmarks with checkpoint/resume support.\n",
        "\n",
        "**Process:**\n",
        "1. Load model directly from HuggingFace Hub (no pruning applied)\n",
        "2. Calculate model statistics (parameters, size)\n",
        "3. Run evaluation with checkpoint system (saves progress after each task)\n",
        "4. Clear GPU memory before next model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"üöÄ STARTING EVALUATION\")\n",
        "print(f\"{'='*70}\\n\")\n",
        "\n",
        "all_model_results = {}\n",
        "\n",
        "for i, model_id in enumerate(unique_models, 1):\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"üìä MODEL {i}/{len(unique_models)}: {model_id}\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "\n",
        "    try:\n",
        "        # 1. Load model from HuggingFace Hub (NO pruning)\n",
        "        print(f\"Loading from HuggingFace Hub...\")\n",
        "        model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_id,\n",
        "            torch_dtype=torch.bfloat16,  # Use bfloat16 for A100, float16 for T4/L4\n",
        "            device_map=\"auto\"\n",
        "        )\n",
        "\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "        if tokenizer.pad_token is None:\n",
        "            tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "        print(\"‚úÖ Model loaded successfully\\n\")\n",
        "\n",
        "        # 2. Display model statistics\n",
        "        stats = get_model_stats(model)\n",
        "        print(f\"üìà Model Statistics:\")\n",
        "        print(f\"   Parameters: {stats['total_parameters']:,}\")\n",
        "        print(f\"   Size: {stats['size_gb']:.2f} GB\\n\")\n",
        "\n",
        "        # 3. Generate checkpoint path automatically\n",
        "        checkpoint_path = get_checkpoint_path(model_id, CHECKPOINT_BASE_DIR)\n",
        "        print(f\"üìÅ Checkpoint: {checkpoint_path}\\n\")\n",
        "\n",
        "        # 4. Run evaluation with checkpoint/resume support\n",
        "        results = run_robust_evaluation(\n",
        "            model=model,\n",
        "            tokenizer=tokenizer,\n",
        "            tasks=BENCHMARKS_BASE,\n",
        "            checkpoint_path=checkpoint_path,\n",
        "            model_name=model_id,\n",
        "        )\n",
        "\n",
        "        all_model_results[model_id] = results\n",
        "\n",
        "        print(f\"\\n‚úÖ Completed: {model_id}\")\n",
        "        print(\"\\nResults Preview:\")\n",
        "        print(format_results_table(results))\n",
        "\n",
        "        # 5. Cleanup memory before next model\n",
        "        del model, tokenizer\n",
        "        clear_gpu_cache()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå ERROR evaluating {model_id}: {str(e)}\")\n",
        "\n",
        "        # Check for common issues\n",
        "        if \"401\" in str(e) or \"403\" in str(e):\n",
        "            print(\"   ‚Üí Authentication required. Run: huggingface-cli login\")\n",
        "        elif \"CUDA out of memory\" in str(e):\n",
        "            print(\"   ‚Üí GPU OOM. Try reducing batch size or using smaller model\")\n",
        "\n",
        "        print(\"   ‚Üí Continuing with next model...\\n\")\n",
        "\n",
        "        # Cleanup and continue\n",
        "        if 'model' in locals():\n",
        "            del model\n",
        "        if 'tokenizer' in locals():\n",
        "            del tokenizer\n",
        "        clear_gpu_cache()\n",
        "        continue\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"‚úÖ EVALUATION COMPLETE: {len(all_model_results)}/{len(unique_models)} models\")\n",
        "print(f\"{'='*70}\\n\")"
      ],
      "metadata": {
        "id": "7_RshCOsC6m7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjcHGNrsIvXH"
      },
      "source": [
        "# 4. Results Consolidation\n",
        "\n",
        "Load checkpoint files and consolidate into a single DataFrame for analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtbaAsxIIvXH",
        "outputId": "4866186d-bcd6-4b03-8859-e7dedf822d84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 637
        }
      },
      "source": [
        "import glob\n",
        "import json\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# --- 1. Funci√≥n auxiliar para arreglar los datos anidados (MMLU) ---\n",
        "def flatten_metrics(metrics, prefix=''):\n",
        "    flat = {}\n",
        "    for k, v in metrics.items():\n",
        "        if isinstance(v, dict):\n",
        "            flat.update(flatten_metrics(v, prefix=f\"{prefix}{k}_\"))\n",
        "        else:\n",
        "            flat[f\"{prefix}{k}\"] = v\n",
        "    return flat\n",
        "\n",
        "# --- 2. Configuraci√≥n ---\n",
        "print(f\"{'='*70}\")\n",
        "print(\" CONSOLIDATING RESULTS (FILTERED)\")\n",
        "print(f\"{'='*70}\\n\")\n",
        "\n",
        "# Buscamos todos los JSONs recursivamente\n",
        "checkpoint_files = glob.glob(f\"{CHECKPOINT_BASE_DIR}/**/*.json\", recursive=True)\n",
        "print(f\"Total archivos JSON encontrados: {len(checkpoint_files)}\")\n",
        "\n",
        "consolidated_data = []\n",
        "\n",
        "for json_path in sorted(checkpoint_files):\n",
        "    # --- FILTRO CLAVE: Ignorar carpetas temporales ---\n",
        "    if \"lm_evals\" in json_path:\n",
        "        continue  # Saltamos este archivo silenciosamente\n",
        "    # -------------------------------------------------\n",
        "\n",
        "    print(f\" Procesando: {os.path.basename(json_path)}\")\n",
        "\n",
        "    try:\n",
        "        with open(json_path, 'r') as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        # Extracci√≥n de metadatos\n",
        "        metadata = data.get(\"metadata\", {})\n",
        "        model_name = metadata.get(\"model_name\", \"Unknown\")\n",
        "\n",
        "        # Determinamos el tama√±o (seg√∫n tu l√≥gica o fallback simple)\n",
        "        if \"1b\" in model_name.lower(): model_size = \"1b\"\n",
        "        elif \"2b\" in model_name.lower(): model_size = \"2b\"\n",
        "        elif \"3b\" in model_name.lower(): model_size = \"3b\"\n",
        "        else: model_size = \"unknown\"\n",
        "\n",
        "        results = data.get(\"results\", {})\n",
        "\n",
        "        if not results:\n",
        "            print(\"   -> Sin resultados, saltando.\")\n",
        "            continue\n",
        "\n",
        "        # Procesar cada tarea\n",
        "        for task_name, metrics in results.items():\n",
        "            row = {\n",
        "                \"model\": model_name,\n",
        "                \"model_size\": model_size,\n",
        "                \"task\": task_name\n",
        "            }\n",
        "            # Usamos la funci√≥n flatten para evitar errores de formato\n",
        "            row.update(flatten_metrics(metrics))\n",
        "            consolidated_data.append(row)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"   -> Error leyendo {json_path}: {e}\")\n",
        "\n",
        "# --- 3. Crear DataFrame Final ---\n",
        "if consolidated_data:\n",
        "    df = pd.DataFrame(consolidated_data)\n",
        "    # Ordenamos: Modelo -> Tarea\n",
        "    df = df.sort_values(by=[\"model\", \"task\"]).reset_index(drop=True)\n",
        "\n",
        "    print(f\"\\n‚úÖ √âXITO: Se han consolidado {len(df)} filas correctamente.\")\n",
        "    print(f\"Modelos √∫nicos: {df['model'].unique()}\")\n",
        "\n",
        "    # Mostrar vista previa\n",
        "    display(df.head())\n",
        "\n",
        "    # Guardar (usando tus rutas originales)\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    df.to_csv(f\"{RESULTS_DIR}/base_models_results_{timestamp}.csv\", index=False)\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è No se encontraron datos v√°lidos despu√©s del filtrado.\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            " CONSOLIDATING RESULTS (FILTERED)\n",
            "======================================================================\n",
            "\n",
            "Total archivos JSON encontrados: 10\n",
            " Procesando: meta_llama_llama_3.2_1b.json\n",
            " Procesando: bsc_lt_salamandra_2b.json\n",
            " Procesando: meta_llama_llama_3.2_3b.json\n",
            "\n",
            "‚úÖ √âXITO: Se han consolidado 42 filas correctamente.\n",
            "Modelos √∫nicos: ['BSC-LT/salamandra-2b' 'meta-llama/Llama-3.2-1B'\n",
            " 'meta-llama/Llama-3.2-3B']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                  model model_size               task word_perplexity,none  \\\n",
              "0  BSC-LT/salamandra-2b         2b      arc_challenge                  NaN   \n",
              "1  BSC-LT/salamandra-2b         2b             arc_es                  NaN   \n",
              "2  BSC-LT/salamandra-2b         2b  belebele_spa_Latn                  NaN   \n",
              "3  BSC-LT/salamandra-2b         2b     global_mmlu_es                  NaN   \n",
              "4  BSC-LT/salamandra-2b         2b              gsm8k                  NaN   \n",
              "\n",
              "  byte_perplexity,none bits_per_byte,none perplexity word_perplexity  \\\n",
              "0                  NaN                NaN        NaN             NaN   \n",
              "1                  NaN                NaN        NaN             NaN   \n",
              "2                  NaN                NaN        NaN             NaN   \n",
              "3                  NaN                NaN        NaN             NaN   \n",
              "4                  NaN                NaN        NaN             NaN   \n",
              "\n",
              "  bits_per_byte prompt_level_strict_acc,none  ...  \\\n",
              "0           NaN                          NaN  ...   \n",
              "1           NaN                          NaN  ...   \n",
              "2           NaN                          NaN  ...   \n",
              "3           NaN                          NaN  ...   \n",
              "4           NaN                          NaN  ...   \n",
              "\n",
              "  subcategories_elementary_mathematics subcategories_high_school_biology  \\\n",
              "0                                  NaN                               NaN   \n",
              "1                                  NaN                               NaN   \n",
              "2                                  NaN                               NaN   \n",
              "3                                  NaN                               NaN   \n",
              "4                                  NaN                               NaN   \n",
              "\n",
              "  subcategories_high_school_chemistry  \\\n",
              "0                                 NaN   \n",
              "1                                 NaN   \n",
              "2                                 NaN   \n",
              "3                                 NaN   \n",
              "4                                 NaN   \n",
              "\n",
              "  subcategories_high_school_computer_science  \\\n",
              "0                                        NaN   \n",
              "1                                        NaN   \n",
              "2                                        NaN   \n",
              "3                                        NaN   \n",
              "4                                        NaN   \n",
              "\n",
              "  subcategories_high_school_mathematics subcategories_high_school_physics  \\\n",
              "0                                   NaN                               NaN   \n",
              "1                                   NaN                               NaN   \n",
              "2                                   NaN                               NaN   \n",
              "3                                   NaN                               NaN   \n",
              "4                                   NaN                               NaN   \n",
              "\n",
              "  subcategories_high_school_statistics subcategories_machine_learning  \\\n",
              "0                                  NaN                            NaN   \n",
              "1                                  NaN                            NaN   \n",
              "2                                  NaN                            NaN   \n",
              "3                                  NaN                            NaN   \n",
              "4                                  NaN                            NaN   \n",
              "\n",
              "  subcategories_business subcategories_medical  \n",
              "0                    NaN                   NaN  \n",
              "1                    NaN                   NaN  \n",
              "2                    NaN                   NaN  \n",
              "3                 0.3276                0.2500  \n",
              "4                    NaN                   NaN  \n",
              "\n",
              "[5 rows x 88 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ca8ee504-113e-44fd-95b9-ba30a9deeb26\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>model_size</th>\n",
              "      <th>task</th>\n",
              "      <th>word_perplexity,none</th>\n",
              "      <th>byte_perplexity,none</th>\n",
              "      <th>bits_per_byte,none</th>\n",
              "      <th>perplexity</th>\n",
              "      <th>word_perplexity</th>\n",
              "      <th>bits_per_byte</th>\n",
              "      <th>prompt_level_strict_acc,none</th>\n",
              "      <th>...</th>\n",
              "      <th>subcategories_elementary_mathematics</th>\n",
              "      <th>subcategories_high_school_biology</th>\n",
              "      <th>subcategories_high_school_chemistry</th>\n",
              "      <th>subcategories_high_school_computer_science</th>\n",
              "      <th>subcategories_high_school_mathematics</th>\n",
              "      <th>subcategories_high_school_physics</th>\n",
              "      <th>subcategories_high_school_statistics</th>\n",
              "      <th>subcategories_machine_learning</th>\n",
              "      <th>subcategories_business</th>\n",
              "      <th>subcategories_medical</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BSC-LT/salamandra-2b</td>\n",
              "      <td>2b</td>\n",
              "      <td>arc_challenge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BSC-LT/salamandra-2b</td>\n",
              "      <td>2b</td>\n",
              "      <td>arc_es</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>BSC-LT/salamandra-2b</td>\n",
              "      <td>2b</td>\n",
              "      <td>belebele_spa_Latn</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>BSC-LT/salamandra-2b</td>\n",
              "      <td>2b</td>\n",
              "      <td>global_mmlu_es</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.3276</td>\n",
              "      <td>0.2500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>BSC-LT/salamandra-2b</td>\n",
              "      <td>2b</td>\n",
              "      <td>gsm8k</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows √ó 88 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ca8ee504-113e-44fd-95b9-ba30a9deeb26')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ca8ee504-113e-44fd-95b9-ba30a9deeb26 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ca8ee504-113e-44fd-95b9-ba30a9deeb26');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-cb8c83cd-bbb1-4842-a326-14ee23386efe\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cb8c83cd-bbb1-4842-a326-14ee23386efe')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-cb8c83cd-bbb1-4842-a326-14ee23386efe button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "FPoZiAfjIvXH",
        "outputId": "7fbbbafc-cabe-4d99-8696-52a9ee44ff74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üíæ Results saved:\n",
            "   /content/drive/MyDrive/fair_pruning/results/base_models_results_20251206_150732.csv\n",
            "   /content/drive/MyDrive/fair_pruning/results/base_models_results_latest.csv\n",
            "   /content/drive/MyDrive/fair_pruning/results/base_models_results_20251206_150732.json\n",
            "\n",
            "‚úÖ All results exported successfully\n"
          ]
        }
      ],
      "source": [
        "if not df.empty:\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "    # Save detailed results CSV\n",
        "    csv_path = f\"{RESULTS_DIR}/base_models_results_{timestamp}.csv\"\n",
        "    df.to_csv(csv_path, index=False)\n",
        "    print(f\"\\nüíæ Results saved:\")\n",
        "    print(f\"   {csv_path}\")\n",
        "\n",
        "    # Save latest version\n",
        "    latest_csv = f\"{RESULTS_DIR}/base_models_results_latest.csv\"\n",
        "    df.to_csv(latest_csv, index=False)\n",
        "    print(f\"   {latest_csv}\")\n",
        "\n",
        "    # Save JSON format\n",
        "    json_path = f\"{RESULTS_DIR}/base_models_results_{timestamp}.json\"\n",
        "    df.to_json(json_path, orient='records', indent=2)\n",
        "    print(f\"   {json_path}\")\n",
        "\n",
        "    print(f\"\\n‚úÖ All results exported successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1MptG-dIvXH"
      },
      "source": [
        "# 5. Summary Analysis\n",
        "\n",
        "Generate summary statistics comparing models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "A5RqknL6IvXH",
        "outputId": "20e51249-caed-44c6-c95e-11657d65d455",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "üìà SUMMARY STATISTICS\n",
            "======================================================================\n",
            "\n",
            "                  model model_size  avg_accuracy  avg_perplexity  tasks_completed  tasks_with_accuracy  tasks_with_perplexity\n",
            "   BSC-LT/salamandra-2b         2b        0.2919          7.2700               14                   10                      1\n",
            "meta-llama/Llama-3.2-1B         1b        0.3136          5.4300               14                   10                      1\n",
            "meta-llama/Llama-3.2-3B         3b        0.4161          3.8800               14                   10                      1\n",
            "\n",
            "üíæ Summary saved: /content/drive/MyDrive/fair_pruning/results/base_models_summary_20251206_150732.csv\n",
            "\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# --- Celda 5: Summary Analysis Corregida ---\n",
        "if not df.empty:\n",
        "    print(f\"{'='*70}\")\n",
        "    print(\"üìà SUMMARY STATISTICS\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "\n",
        "    summary = []\n",
        "    # Agrupamos por modelo\n",
        "    for model_name, model_df in df.groupby('model'):\n",
        "\n",
        "        # --- CORRECCI√ìN AQU√ç: Convertir a n√∫meros expl√≠citamente ---\n",
        "        # Usamos errors='coerce' para que si hay texto no num√©rico se convierta en NaN\n",
        "        acc_series = pd.to_numeric(model_df['accuracy'], errors='coerce')\n",
        "        ppl_series = pd.to_numeric(model_df['perplexity'], errors='coerce')\n",
        "\n",
        "        # Ahora s√≠ podemos hacer dropna() seguro\n",
        "        acc = acc_series.dropna()\n",
        "        ppl = ppl_series.dropna()\n",
        "        # -----------------------------------------------------------\n",
        "\n",
        "        # Obtener metadata (intentando ser robustos si falta 'model_size')\n",
        "        if 'model_size' in model_df.columns:\n",
        "            model_size = model_df['model_size'].iloc[0]\n",
        "        else:\n",
        "            # Fallback simple si no existe la columna\n",
        "            model_size = \"unknown\"\n",
        "            if \"1b\" in model_name.lower(): model_size = \"1b\"\n",
        "            elif \"2b\" in model_name.lower(): model_size = \"2b\"\n",
        "            elif \"3b\" in model_name.lower(): model_size = \"3b\"\n",
        "\n",
        "        summary.append({\n",
        "            \"model\": model_name,\n",
        "            \"model_size\": model_size,\n",
        "            \"avg_accuracy\": acc.mean() if len(acc) > 0 else None,\n",
        "            \"avg_perplexity\": ppl.mean() if len(ppl) > 0 else None,\n",
        "            \"tasks_completed\": len(model_df),\n",
        "            \"tasks_with_accuracy\": len(acc),\n",
        "            \"tasks_with_perplexity\": len(ppl)\n",
        "        })\n",
        "\n",
        "    summary_df = pd.DataFrame(summary)\n",
        "\n",
        "    if not summary_df.empty:\n",
        "        summary_df = summary_df.sort_values(\"model\").reset_index(drop=True)\n",
        "        # Formato limpio para la tabla\n",
        "        print(summary_df.to_string(index=False, float_format=\"%.4f\"))\n",
        "\n",
        "        # Guardar summary\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        summary_csv = f\"{RESULTS_DIR}/base_models_summary_{timestamp}.csv\"\n",
        "        summary_df.to_csv(summary_csv, index=False)\n",
        "        print(f\"\\nüíæ Summary saved: {summary_csv}\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è No se pudo generar el resumen (datos insuficientes).\")\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "else:\n",
        "    print(\"DataFrame vac√≠o. No hay estad√≠sticas que calcular.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Evaluation Complete\n",
        "\n",
        "## Summary\n",
        "\n",
        "Baseline performance metrics established for the Fairness Pruning project.\n",
        "\n",
        "**Generated Files:**\n",
        "- `base_models_results_latest.csv` - Full evaluation results\n",
        "- `base_models_results_YYYYMMDD_HHMMSS.json` - Structured export\n",
        "- `base_models_summary_YYYYMMDD_HHMMSS.csv` - Summary metrics\n",
        "- Individual checkpoint JSONs per model (in subdirectories by size)\n",
        "\n",
        "**Next Steps:**\n",
        "1. Use these baselines as reference for bias mitigation experiments\n",
        "2. Identify high-variance tasks that may be sensitive to interventions\n",
        "3. Proceed to bias detection and pruning notebooks\n",
        "\n",
        "---\n",
        "\n",
        "**Powered by OptiPFair** - Activation-Guided MLP Width Pruning for Bias Mitigation\n",
        "\n",
        "If this research helps your work:\n",
        "- ‚≠ê Star [the repo](https://github.com/peremartra/optipfair)\n",
        "- üìñ Read the [documentation](https://peremartra.github.io/optipfair/)\n",
        "- üêõ Report issues or suggest features\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "TBPO5o8oteVs",
        "outputId": "b390b8a6-821f-47b6-b7bd-30eb977ac374"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"{'='*70}\")\n",
        "print(\"üìÅ GENERATED FILES\")\n",
        "print(f\"{'='*70}\\n\")\n",
        "\n",
        "print(\"Results:\")\n",
        "if 'csv_path' in locals() and os.path.exists(csv_path):\n",
        "    print(f\"  ‚úÖ {csv_path}\")\n",
        "if 'latest_csv' in locals() and os.path.exists(latest_csv):\n",
        "    print(f\"  ‚úÖ {latest_csv}\")\n",
        "if 'json_path' in locals() and os.path.exists(json_path):\n",
        "    print(f\"  ‚úÖ {json_path}\")\n",
        "if 'summary_csv' in locals() and os.path.exists(summary_csv):\n",
        "    print(f\"  ‚úÖ {summary_csv}\")\n",
        "\n",
        "print(\"\\nCheckpoints:\")\n",
        "if 'checkpoint_files' in locals():\n",
        "    for f in sorted(checkpoint_files)[:10]:  # Show first 10\n",
        "        print(f\"  ‚úÖ {f}\")\n",
        "    if len(checkpoint_files) > 10:\n",
        "        print(f\"  ... and {len(checkpoint_files) - 10} more\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"‚úÖ EVALUATION COMPLETE\")\n",
        "print(f\"{'='*70}\")"
      ],
      "metadata": {
        "id": "ENb-L1tWhrRg",
        "outputId": "03f35015-33a7-4155-ddad-380b4e4602cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "üìÅ GENERATED FILES\n",
            "======================================================================\n",
            "\n",
            "Results:\n",
            "  ‚úÖ /content/drive/MyDrive/fair_pruning/results/base_models_results_20251206_150732.csv\n",
            "  ‚úÖ /content/drive/MyDrive/fair_pruning/results/base_models_results_latest.csv\n",
            "  ‚úÖ /content/drive/MyDrive/fair_pruning/results/base_models_results_20251206_150732.json\n",
            "  ‚úÖ /content/drive/MyDrive/fair_pruning/results/base_models_summary_20251206_150732.csv\n",
            "\n",
            "Checkpoints:\n",
            "  ‚úÖ /content/drive/MyDrive/fair_pruning/checkpoints/1b/meta_llama_llama_3.2_1b.json\n",
            "  ‚úÖ /content/drive/MyDrive/fair_pruning/checkpoints/2b/bsc_lt_salamandra_2b.json\n",
            "  ‚úÖ /content/drive/MyDrive/fair_pruning/checkpoints/3b/meta_llama_llama_3.2_3b.json\n",
            "  ‚úÖ /content/drive/MyDrive/fair_pruning/checkpoints/results/lm_evals/bsc_lt_salamandra_2b_veritas_qa_ca.json\n",
            "  ‚úÖ /content/drive/MyDrive/fair_pruning/checkpoints/results/lm_evals/bsc_lt_salamandra_2b_veritas_qa_es.json\n",
            "  ‚úÖ /content/drive/MyDrive/fair_pruning/checkpoints/results/lm_evals/meta_llama_llama_3.2_1b_truthfulqa_mc2.json\n",
            "  ‚úÖ /content/drive/MyDrive/fair_pruning/checkpoints/results/lm_evals/meta_llama_llama_3.2_1b_veritas_qa_ca.json\n",
            "  ‚úÖ /content/drive/MyDrive/fair_pruning/checkpoints/results/lm_evals/meta_llama_llama_3.2_1b_veritas_qa_es.json\n",
            "  ‚úÖ /content/drive/MyDrive/fair_pruning/checkpoints/results/lm_evals/meta_llama_llama_3.2_3b_veritas_qa_ca.json\n",
            "  ‚úÖ /content/drive/MyDrive/fair_pruning/checkpoints/results/lm_evals/meta_llama_llama_3.2_3b_veritas_qa_es.json\n",
            "\n",
            "======================================================================\n",
            "‚úÖ EVALUATION COMPLETE\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mc2FNF5NThaA"
      },
      "execution_count": 13,
      "outputs": []
    }
  ]
}