{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/peremartra/fairness-pruning/blob/main/notebooks/02_Evaluate_BBQ.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzfjNg_SIvXD"
      },
      "source": [
        "# Fairness Pruning Research - Base Model Evaluation\n",
        "## 02 - Comprehensive Benchmark Suite for Unpruned Models\n",
        "\n",
        "### Establishing Performance Bias using BBVQ, EsBBQ & CatBBQ for Bias Mitigation Research\n",
        "by [Pere Martra](https://github.com/peremartra)\n",
        "\n",
        "[![GitHub](https://img.shields.io/badge/â­_Star-OptiPFair-orange?logo=github&logoColor=white)](https://github.com/peremartra/optipfair)\n",
        "[![PyPI](https://img.shields.io/pypi/v/optipfair?logo=python&logoColor=white&label=v)](https://pypi.org/project/optipfair/)\n",
        "\n",
        "**Repository:** [github.com/peremartra/fairness-pruning](https://github.com/peremartra/fairness-pruning)\n",
        "\n",
        "---\n",
        "\n",
        "**Colab Environment:** GPU L4 or A100\n",
        "\n",
        "**Models to Evaluate:**\n",
        "* Llama-3.2-1B (base)\n",
        "* Llama-3.2-3B (base)\n",
        "* Salamandra-2B (base)\n",
        "---\n",
        "\n",
        "**Note:** This notebook evaluates ONLY base models (no pruning applied). For bias mitigation experiments with pruned models, see subsequent notebooks.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkVFbeCMIvXF"
      },
      "source": [
        "# 1. Setup & Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAo67s0lIvXF",
        "outputId": "fb2d84fb-f8b3-4606-c8a9-ca5ff09f81ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m52.2/52.2 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m53.8/53.8 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m97.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m293.6/293.6 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m91.1/91.1 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Install required libraries\n",
        "!pip install -q optipfair\n",
        "!pip install -q lm-eval\n",
        "!pip install -q langdetect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWIHQuIGIvXG",
        "outputId": "2b835322-d95f-4e15-8cfd-c683acc18391"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive for checkpoint persistence\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DG2nO7YpIvXG",
        "outputId": "360f338c-867d-4a1c-e86b-f44f28bb1989"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… utils.py downloaded successfully\n"
          ]
        }
      ],
      "source": [
        "# Download utils.py from GitHub repository\n",
        "!wget -q https://raw.githubusercontent.com/peremartra/fairness-pruning/main/utils.py\n",
        "\n",
        "# Verify download\n",
        "import os\n",
        "if os.path.exists('utils.py'):\n",
        "    print(\"âœ… utils.py downloaded successfully\")\n",
        "else:\n",
        "    print(\"âŒ Failed to download utils.py\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "gQKRdEHcSFYK"
      },
      "outputs": [],
      "source": [
        "!wget -q https://raw.githubusercontent.com/peremartra/fairness-pruning/main/veritas_qa_ca.yaml\n",
        "!wget -q https://raw.githubusercontent.com/peremartra/fairness-pruning/main/veritas_qa_es.yaml\n",
        "!wget -q https://raw.githubusercontent.com/peremartra/fairness-pruning/main/veritas_lm.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSOqtWXbhrRf"
      },
      "source": [
        "# 1. Helper Functions\n",
        "\n",
        "Utility functions for automatic checkpoint path generation and model size detection."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goJTl4XJQjL6"
      },
      "source": [
        "# 2. Configuration & Evaluation Plan (BBQ-only)\n",
        "\n",
        "Configure paths, select the BBQ task, and list the models we will evaluate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EG53MfrJQjL6",
        "outputId": "51948549-a389-481d-8fd2-bc94e6bb31ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "ðŸ“Š EVALUATION PLAN: BBQ-only\n",
            "======================================================================\n",
            "Checkpoints: /content/drive/MyDrive/fair_pruning/checkpoints_bbq\n",
            "Results: /content/drive/MyDrive/fair_pruning/results\n",
            "Tasks: ['bbq']\n",
            "Models:\n",
            " - BSC-LT/salamandra-2b\n",
            " - meta-llama/Llama-3.2-1B\n",
            " - meta-llama/Llama-3.2-3B\n",
            "======================================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import json\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "import logging\n",
        "import os\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from IPython.display import display\n",
        "from utils import (\n",
        "    EXPERIMENT_CONFIG,\n",
        "    run_robust_evaluation,\n",
        "    load_or_create_model,\n",
        "    clear_gpu_cache,\n",
        "    format_results_table,\n",
        "    get_model_stats,\n",
        " )\n",
        "\n",
        "# Paths (Drive recommended in Colab)\n",
        "CHECKPOINT_BASE_DIR = \"/content/drive/MyDrive/fair_pruning/checkpoints_bbq\"\n",
        "RESULTS_DIR = \"/content/drive/MyDrive/fair_pruning/results\"\n",
        "Path(RESULTS_DIR).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# BBQ task list (0-shot)\n",
        "BBQ_TASKS = [{\"name\": \"bbq\", \"num_fewshot\": 0}]\n",
        "\n",
        "# De-duplicate models from EXPERIMENT_CONFIG\n",
        "unique_models = list(dict.fromkeys([cfg[\"base_model\"] for cfg in EXPERIMENT_CONFIG]))\n",
        "\n",
        "logging.getLogger(\"lm_eval\").setLevel(logging.INFO)\n",
        "\n",
        "print(f\"{'='*70}\")\n",
        "print(\"ðŸ“Š EVALUATION PLAN: BBQ-only\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"Checkpoints: {CHECKPOINT_BASE_DIR}\")\n",
        "print(f\"Results: {RESULTS_DIR}\")\n",
        "print(f\"Tasks: {[task['name'] for task in BBQ_TASKS]}\")\n",
        "print(\"Models:\")\n",
        "for m in unique_models:\n",
        "    print(f\" - {m}\")\n",
        "print(f\"{'='*70}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vb0Sq8eqhrRg",
        "outputId": "41144d6f-b761-4966-dbfb-4094717997e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing helper functions with EXPERIMENT_CONFIG:\n",
            "----------------------------------------------------------------------\n",
            "BSC-LT/salamandra-2b                               â†’ 2b\n",
            "meta-llama/Llama-3.2-1B                            â†’ 1b\n",
            "meta-llama/Llama-3.2-3B                            â†’ 3b\n",
            "----------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import os\n",
        "\n",
        "def get_model_size(model_name: str) -> str:\n",
        "    \"\"\"Extract model size identifier from HuggingFace model name.\n",
        "\n",
        "    Examples:\n",
        "        \"meta-llama/Llama-3.2-1B\" â†’ \"1b\"\n",
        "        \"meta-llama/Llama-3.2-3B-Instruct\" â†’ \"3b_instruct\"\n",
        "        \"BSC-LT/salamandra-2b\" â†’ \"2b\"\n",
        "    \"\"\"\n",
        "    match = re.search(r'(\\d+\\.?\\d*)[Bb]', model_name)\n",
        "    if not match:\n",
        "        return \"unknown\"\n",
        "\n",
        "    size = match.group(1).replace('.', '_') + \"b\"\n",
        "    if \"instruct\" in model_name.lower():\n",
        "        size += \"_instruct\"\n",
        "\n",
        "    return size.lower()\n",
        "\n",
        "def get_checkpoint_path(model_name: str, base_dir: str) -> str:\n",
        "    \"\"\"Generate checkpoint path with size-based subdirectory.\n",
        "\n",
        "    Args:\n",
        "        model_name: Full HuggingFace model identifier\n",
        "        base_dir: Base directory for checkpoints\n",
        "\n",
        "    Returns:\n",
        "        Full path to checkpoint file\n",
        "    \"\"\"\n",
        "    model_size = get_model_size(model_name)\n",
        "    safe_name = model_name.replace('/', '_').replace('-', '_').lower()\n",
        "    checkpoint_dir = os.path.join(base_dir, model_size)\n",
        "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "    return os.path.join(checkpoint_dir, f\"{safe_name}.json\")\n",
        "\n",
        "# Test with EXPERIMENT_CONFIG\n",
        "print(\"Testing helper functions with EXPERIMENT_CONFIG:\")\n",
        "print(\"-\" * 70)\n",
        "for cfg in EXPERIMENT_CONFIG:\n",
        "    model_id = cfg['base_model']\n",
        "    size = get_model_size(model_id)\n",
        "    print(f\"{model_id:<50} â†’ {size}\")\n",
        "print(\"-\" * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYSCTWcyQjL6"
      },
      "source": [
        "# 3. Run BBQ Evaluation\n",
        "\n",
        "Evaluate each base model on the BBQ task with checkpoint/resume and raw result saving."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sx4LW8uCQjL6"
      },
      "outputs": [],
      "source": [
        "print(f\"\\n{'='*70}\")\n",
        "print(\"ðŸš€ STARTING BBQ EVALUATION (Hugging Face Native Loading)\")\n",
        "print(f\"{'='*70}\\n\")\n",
        "\n",
        "all_model_results = {}\n",
        "\n",
        "for idx, model_id in enumerate(unique_models, 1):\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"ðŸ“Š MODEL {idx}/{len(unique_models)}: {model_id}\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "    try:\n",
        "        # Generar ruta de checkpoint\n",
        "        checkpoint_path = get_checkpoint_path(model_id, CHECKPOINT_BASE_DIR)\n",
        "\n",
        "        # --- CARGA DIRECTA CON HUGGING FACE ---\n",
        "        print(f\"ðŸ“¥ Loading directly from Hugging Face Hub...\")\n",
        "        model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_id,\n",
        "            torch_dtype=torch.bfloat16,\n",
        "            device_map=\"auto\"\n",
        "        )\n",
        "\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "        if tokenizer.pad_token is None:\n",
        "            tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "        print(\"âœ… Model loaded successfully (Native HF)\")\n",
        "\n",
        "        # Mostrar estadÃ­sticas\n",
        "        stats = get_model_stats(model)\n",
        "        print(f\"ðŸ“ˆ Params: {stats['total_parameters']:,} | Size: {stats['size_gb']:.2f} GB\")\n",
        "        print(f\"ðŸ“ Checkpoint: {checkpoint_path}\\n\")\n",
        "\n",
        "        # --- EJECUTAR EVALUACIÃ“N (Llamada corregida) ---\n",
        "        # Eliminados 'save_raw_results' y 'raw_results_dir' porque utils.py no los admite\n",
        "        results = run_robust_evaluation(\n",
        "            model=model,\n",
        "            tokenizer=tokenizer,\n",
        "            tasks=BBQ_TASKS,\n",
        "            checkpoint_path=checkpoint_path,\n",
        "            model_name=model_id\n",
        "        )\n",
        "        # -----------------------------------------------\n",
        "\n",
        "        all_model_results[model_id] = results\n",
        "        print(f\"\\nâœ… Completed: {model_id}\")\n",
        "        print(\"Results Preview:\")\n",
        "        print(format_results_table(results))\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nâŒ ERROR evaluating {model_id}: {e}\")\n",
        "        if 'model' in locals(): del model\n",
        "        if 'tokenizer' in locals(): del tokenizer\n",
        "        clear_gpu_cache()\n",
        "        continue\n",
        "\n",
        "    # Limpieza de memoria\n",
        "    del model\n",
        "    del tokenizer\n",
        "    clear_gpu_cache()\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"âœ… BBQ EVALUATION COMPLETE: {len(all_model_results)}/{len(unique_models)} models\")\n",
        "print(f\"{'='*70}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R20JPHfQQjL7"
      },
      "source": [
        "# 4. Consolidate BBQ Results\n",
        "\n",
        "Load checkpoint files, flatten metrics, and export combined BBQ results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "5R9TwH-iQjL7",
        "outputId": "95e0749a-d065-48d6-c385-3fc0960ae7d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            " CONSOLIDATING BBQ RESULTS\n",
            "======================================================================\n",
            "\n",
            "Total checkpoint JSONs: 6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                     model model_size task accuracy acc_norm\n",
              "0     BSC-LT/salamandra-2b         2b  bbq   0.2905      N/A\n",
              "1  meta-llama/Llama-3.2-1B         1b  bbq   0.3115      N/A\n",
              "2  meta-llama/Llama-3.2-3B         3b  bbq   0.4052      N/A"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ba8c029f-2241-441d-bea8-0e9b6f68acc5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>model_size</th>\n",
              "      <th>task</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>acc_norm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BSC-LT/salamandra-2b</td>\n",
              "      <td>2b</td>\n",
              "      <td>bbq</td>\n",
              "      <td>0.2905</td>\n",
              "      <td>N/A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>meta-llama/Llama-3.2-1B</td>\n",
              "      <td>1b</td>\n",
              "      <td>bbq</td>\n",
              "      <td>0.3115</td>\n",
              "      <td>N/A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>meta-llama/Llama-3.2-3B</td>\n",
              "      <td>3b</td>\n",
              "      <td>bbq</td>\n",
              "      <td>0.4052</td>\n",
              "      <td>N/A</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ba8c029f-2241-441d-bea8-0e9b6f68acc5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ba8c029f-2241-441d-bea8-0e9b6f68acc5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ba8c029f-2241-441d-bea8-0e9b6f68acc5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-40a2877d-25c8-47ad-aa3f-2d45b08feaef\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-40a2877d-25c8-47ad-aa3f-2d45b08feaef')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-40a2877d-25c8-47ad-aa3f-2d45b08feaef button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    print(\\\"\\u26a0\\ufe0f No BBQ results found to consolidate\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"BSC-LT/salamandra-2b\",\n          \"meta-llama/Llama-3.2-1B\",\n          \"meta-llama/Llama-3.2-3B\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model_size\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"2b\",\n          \"1b\",\n          \"3b\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"task\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"bbq\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"accuracy\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"0.2905\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"acc_norm\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"N/A\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ’¾ BBQ results saved:\n",
            "   /content/drive/MyDrive/fair_pruning/results/base_models_bbq_results_20251207_191101.csv\n",
            "   /content/drive/MyDrive/fair_pruning/results/base_models_bbq_results_latest.csv\n",
            "   /content/drive/MyDrive/fair_pruning/results/base_models_bbq_results_20251207_191101.json\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "\n",
        "def flatten_metrics(metrics, prefix=''):\n",
        "    flat = {}\n",
        "    for k, v in metrics.items():\n",
        "        if isinstance(v, dict):\n",
        "            flat.update(flatten_metrics(v, prefix=f\"{prefix}{k}_\"))\n",
        "        else:\n",
        "            flat[f\"{prefix}{k}\"] = v\n",
        "    return flat\n",
        "\n",
        "print(f\"{'='*70}\")\n",
        "print(\" CONSOLIDATING BBQ RESULTS\")\n",
        "print(f\"{'='*70}\\n\")\n",
        "\n",
        "checkpoint_files = glob.glob(f\"{CHECKPOINT_BASE_DIR}/**/*.json\", recursive=True)\n",
        "print(f\"Total checkpoint JSONs: {len(checkpoint_files)}\")\n",
        "\n",
        "consolidated_data = []\n",
        "\n",
        "for json_path in sorted(checkpoint_files):\n",
        "    if \"lm_evals\" in json_path:\n",
        "        continue  # skip raw per-task dumps\n",
        "    try:\n",
        "        with open(json_path, \"r\") as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        metadata = data.get(\"metadata\", {})\n",
        "        model_name = metadata.get(\"model_name\", \"Unknown\")\n",
        "\n",
        "        if \"1b\" in model_name.lower(): model_size = \"1b\"\n",
        "        elif \"2b\" in model_name.lower(): model_size = \"2b\"\n",
        "        elif \"3b\" in model_name.lower(): model_size = \"3b\"\n",
        "        else: model_size = \"unknown\"\n",
        "\n",
        "        results = data.get(\"results\", {})\n",
        "        if not results:\n",
        "            continue\n",
        "\n",
        "        for task_name, metrics in results.items():\n",
        "            row = {\n",
        "                \"model\": model_name,\n",
        "                \"model_size\": model_size,\n",
        "                \"task\": task_name,\n",
        "            }\n",
        "            row.update(flatten_metrics(metrics))\n",
        "            consolidated_data.append(row)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"   -> Error reading {json_path}: {e}\")\n",
        "\n",
        "if consolidated_data:\n",
        "    df = pd.DataFrame(consolidated_data)\n",
        "    df = df.sort_values(by=[\"model\", \"task\"]).reset_index(drop=True)\n",
        "    display(df.head())\n",
        "\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    csv_path = f\"{RESULTS_DIR}/base_models_bbq_results_{timestamp}.csv\"\n",
        "    latest_csv = f\"{RESULTS_DIR}/base_models_bbq_results_latest.csv\"\n",
        "    json_path = f\"{RESULTS_DIR}/base_models_bbq_results_{timestamp}.json\"\n",
        "\n",
        "    df.to_csv(csv_path, index=False)\n",
        "    df.to_csv(latest_csv, index=False)\n",
        "    df.to_json(json_path, orient=\"records\", indent=2)\n",
        "\n",
        "    print(\"\\nðŸ’¾ BBQ results saved:\")\n",
        "    print(f\"   {csv_path}\")\n",
        "    print(f\"   {latest_csv}\")\n",
        "    print(f\"   {json_path}\")\n",
        "else:\n",
        "    print(\"âš ï¸ No BBQ results found to consolidate.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-EPjbK_QjL7"
      },
      "source": [
        "# 5. Summary Analysis\n",
        "\n",
        "Quick per-model accuracy summary for BBQ and file inventory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDBqo_5iQjL7",
        "outputId": "71e0eedc-739c-4119-c209-7a7f5a3f5c11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "ðŸ“ˆ BBQ SUMMARY\n",
            "======================================================================\n",
            "                  model model_size  avg_accuracy  tasks_completed\n",
            "   BSC-LT/salamandra-2b         2b        0.2905                1\n",
            "meta-llama/Llama-3.2-1B         1b        0.3115                1\n",
            "meta-llama/Llama-3.2-3B         3b        0.4052                1\n",
            "\n",
            "ðŸ’¾ Summary saved: /content/drive/MyDrive/fair_pruning/results/base_models_bbq_summary_20251207_191101.csv\n",
            "\n",
            "======================================================================\n",
            "ðŸ“ GENERATED FILES\n",
            "======================================================================\n",
            "  âœ… /content/drive/MyDrive/fair_pruning/results/base_models_bbq_results_20251207_191101.csv\n",
            "  âœ… /content/drive/MyDrive/fair_pruning/results/base_models_bbq_results_latest.csv\n",
            "  âœ… /content/drive/MyDrive/fair_pruning/results/base_models_bbq_results_20251207_191101.json\n",
            "  âœ… /content/drive/MyDrive/fair_pruning/results/base_models_bbq_summary_20251207_191101.csv\n",
            "\n",
            "Checkpoints (first 10):\n",
            "  âœ… /content/drive/MyDrive/fair_pruning/checkpoints_bbq/1b/meta_llama_llama_3.2_1b.json\n",
            "  âœ… /content/drive/MyDrive/fair_pruning/checkpoints_bbq/2b/bsc_lt_salamandra_2b.json\n",
            "  âœ… /content/drive/MyDrive/fair_pruning/checkpoints_bbq/3b/meta_llama_llama_3.2_3b.json\n",
            "  âœ… /content/drive/MyDrive/fair_pruning/checkpoints_bbq/results/lm_evals/bsc_lt_salamandra_2b_bbq.json\n",
            "  âœ… /content/drive/MyDrive/fair_pruning/checkpoints_bbq/results/lm_evals/meta_llama_llama_3.2_1b_bbq.json\n",
            "  âœ… /content/drive/MyDrive/fair_pruning/checkpoints_bbq/results/lm_evals/meta_llama_llama_3.2_3b_bbq.json\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# Summary stats\n",
        "summary_df = None\n",
        "if 'df' in locals() and not df.empty:\n",
        "    summaries = []\n",
        "    for model_name, model_df in df.groupby('model'):\n",
        "        acc_series = pd.to_numeric(model_df.get('accuracy'), errors='coerce').dropna()\n",
        "        summaries.append({\n",
        "            \"model\": model_name,\n",
        "            \"model_size\": model_df.get('model_size', pd.Series(['unknown'])).iloc[0],\n",
        "            \"avg_accuracy\": acc_series.mean() if len(acc_series) else None,\n",
        "            \"tasks_completed\": len(model_df)\n",
        "        })\n",
        "\n",
        "    summary_df = pd.DataFrame(summaries)\n",
        "    summary_df = summary_df.sort_values(\"model\").reset_index(drop=True)\n",
        "    print(f\"{'='*70}\")\n",
        "    print(\"ðŸ“ˆ BBQ SUMMARY\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(summary_df.to_string(index=False, float_format=\"%.4f\"))\n",
        "\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    summary_csv = f\"{RESULTS_DIR}/base_models_bbq_summary_{timestamp}.csv\"\n",
        "    summary_df.to_csv(summary_csv, index=False)\n",
        "    print(f\"\\nðŸ’¾ Summary saved: {summary_csv}\\n\")\n",
        "else:\n",
        "    print(\"No consolidated data available for summary.\")\n",
        "\n",
        "print(f\"{'='*70}\")\n",
        "print(\"ðŸ“ GENERATED FILES\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "if 'csv_path' in locals() and os.path.exists(csv_path):\n",
        "    print(f\"  âœ… {csv_path}\")\n",
        "if 'latest_csv' in locals() and os.path.exists(latest_csv):\n",
        "    print(f\"  âœ… {latest_csv}\")\n",
        "if 'json_path' in locals() and os.path.exists(json_path):\n",
        "    print(f\"  âœ… {json_path}\")\n",
        "if 'summary_csv' in locals() and os.path.exists(summary_csv):\n",
        "    print(f\"  âœ… {summary_csv}\")\n",
        "\n",
        "print(\"\\nCheckpoints (first 10):\")\n",
        "if 'checkpoint_files' in locals():\n",
        "    for f in sorted(checkpoint_files)[:10]:\n",
        "        print(f\"  âœ… {f}\")\n",
        "    if len(checkpoint_files) > 10:\n",
        "        print(f\"  ... and {len(checkpoint_files) - 10} more\")\n",
        "\n",
        "print(f\"{'='*70}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tDatEjSVRL-C"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}