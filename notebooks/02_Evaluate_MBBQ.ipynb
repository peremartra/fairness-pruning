{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/peremartra/fairness-pruning/blob/main/notebooks/02_Evaluate_MBBQ.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzfjNg_SIvXD"
      },
      "source": [
        "# Fairness Pruning Research - MBBQ (EsBBQ) Evaluation\n",
        "## 02 - Multilingual BBQ Benchmark for Spanish Bias Detection\n",
        "\n",
        "### Establishing Bias Performance using EsBBQ (MBBQ) for Spanish Bias Mitigation Research\n",
        "by [Pere Martra](https://github.com/peremartra)\n",
        "\n",
        "[![GitHub](https://img.shields.io/badge/‚≠ê_Star-OptiPFair-orange?logo=github&logoColor=white)](https://github.com/peremartra/optipfair)\n",
        "[![PyPI](https://img.shields.io/pypi/v/optipfair?logo=python&logoColor=white&label=v)](https://pypi.org/project/optipfair/)\n",
        "\n",
        "**Repository:** [github.com/peremartra/fairness-pruning](https://github.com/peremartra/fairness-pruning)\n",
        "\n",
        "---\n",
        "\n",
        "**Colab Environment:** GPU L4 or A100\n",
        "\n",
        "**Models to Evaluate:**\n",
        "* Llama-3.2-1B (base)\n",
        "* Llama-3.2-3B (base)\n",
        "* Salamandra-2B (base)\n",
        "\n",
        "**EsBBQ Categories:**\n",
        "* Age, Disability Status, Gender, LGBTQIA+, Nationality\n",
        "* Physical Appearance, Race/Ethnicity, Religion, SES, Spanish Region\n",
        "\n",
        "---\n",
        "\n",
        "**Note:** This notebook evaluates ONLY base models (no pruning applied) on Spanish bias benchmarks. For English BBQ evaluation, see `02_Evaluate_BBQ.ipynb`.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkVFbeCMIvXF"
      },
      "source": [
        "# 1. Setup & Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "nAo67s0lIvXF"
      },
      "outputs": [],
      "source": [
        "# Install required libraries\n",
        "!pip install -q optipfair\n",
        "!pip install -q lm-eval\n",
        "!pip install -q langdetect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "GWIHQuIGIvXG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d1b8d5f-42b3-4ef7-ed0e-508d3818353a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive for checkpoint persistence\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "DG2nO7YpIvXG",
        "outputId": "05b6d47e-b48e-42b5-e731-ba73526cc4e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ utils.py downloaded successfully\n"
          ]
        }
      ],
      "source": [
        "# Download utils.py from GitHub repository\n",
        "!wget -q https://raw.githubusercontent.com/peremartra/fairness-pruning/main/utils.py\n",
        "\n",
        "# Verify download\n",
        "import os\n",
        "if os.path.exists('utils.py'):\n",
        "    print(\"‚úÖ utils.py downloaded successfully\")\n",
        "else:\n",
        "    print(\"‚ùå Failed to download utils.py\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "gQKRdEHcSFYK",
        "outputId": "5df68322-1180-490e-b9f8-46853664510c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üåê Local files not found. Downloading from GitHub...\n",
            "‚úÖ Downloaded 10 EsBBQ YAML files from GitHub.\n"
          ]
        }
      ],
      "source": [
        "# Download EsBBQ task YAML files from GitHub repository\n",
        "import os\n",
        "import shutil\n",
        "os.makedirs('custom_tasks/esbbq', exist_ok=True)\n",
        "\n",
        "# Check if we are in the repo and can use local clean files\n",
        "local_source = '../custom_tasks/esbbq'\n",
        "files_to_copy = [\n",
        "    'esbbq_age.yaml',\n",
        "    'esbbq_disabilitystatus.yaml',\n",
        "    'esbbq_gender.yaml',\n",
        "    'esbbq_lgbtqia.yaml',\n",
        "    'esbbq_nationality.yaml',\n",
        "    'esbbq_physicalappearance.yaml',\n",
        "    'esbbq_raceethnicity.yaml',\n",
        "    'esbbq_religion.yaml',\n",
        "    'esbbq_ses.yaml',\n",
        "    'esbbq_spanishregion.yaml',\n",
        "    'esbbq_utils.py'\n",
        "]\n",
        "\n",
        "used_local = False\n",
        "if os.path.exists(local_source):\n",
        "    print(\"üìÇ Found local custom_tasks in ../custom_tasks. Copying to notebook dir...\")\n",
        "    for fname in files_to_copy:\n",
        "        src = os.path.join(local_source, fname)\n",
        "        dst = os.path.join('custom_tasks/esbbq', fname)\n",
        "        if os.path.exists(src):\n",
        "            shutil.copy(src, dst)\n",
        "            used_local = True\n",
        "\n",
        "if not used_local:\n",
        "    print(\"üåê Local files not found. Downloading from GitHub...\")\n",
        "    !wget -q -P custom_tasks/esbbq https://raw.githubusercontent.com/peremartra/fairness-pruning/main/custom_tasks/esbbq/esbbq_age.yaml\n",
        "    !wget -q -P custom_tasks/esbbq https://raw.githubusercontent.com/peremartra/fairness-pruning/main/custom_tasks/esbbq/esbbq_disabilitystatus.yaml\n",
        "    !wget -q -P custom_tasks/esbbq https://raw.githubusercontent.com/peremartra/fairness-pruning/main/custom_tasks/esbbq/esbbq_gender.yaml\n",
        "    !wget -q -P custom_tasks/esbbq https://raw.githubusercontent.com/peremartra/fairness-pruning/main/custom_tasks/esbbq/esbbq_lgbtqia.yaml\n",
        "    !wget -q -P custom_tasks/esbbq https://raw.githubusercontent.com/peremartra/fairness-pruning/main/custom_tasks/esbbq/esbbq_nationality.yaml\n",
        "    !wget -q -P custom_tasks/esbbq https://raw.githubusercontent.com/peremartra/fairness-pruning/main/custom_tasks/esbbq/esbbq_physicalappearance.yaml\n",
        "    !wget -q -P custom_tasks/esbbq https://raw.githubusercontent.com/peremartra/fairness-pruning/main/custom_tasks/esbbq/esbbq_raceethnicity.yaml\n",
        "    !wget -q -P custom_tasks/esbbq https://raw.githubusercontent.com/peremartra/fairness-pruning/main/custom_tasks/esbbq/esbbq_religion.yaml\n",
        "    !wget -q -P custom_tasks/esbbq https://raw.githubusercontent.com/peremartra/fairness-pruning/main/custom_tasks/esbbq/esbbq_ses.yaml\n",
        "    !wget -q -P custom_tasks/esbbq https://raw.githubusercontent.com/peremartra/fairness-pruning/main/custom_tasks/esbbq/esbbq_spanishregion.yaml\n",
        "    !wget -q -P custom_tasks/esbbq https://raw.githubusercontent.com/peremartra/fairness-pruning/main/custom_tasks/esbbq/esbbq_utils.py\n",
        "\n",
        "# Verify downloads (or copies)\n",
        "yaml_count = len([f for f in os.listdir('custom_tasks/esbbq') if f.endswith('.yaml')])\n",
        "if used_local:\n",
        "    print(f\"‚úÖ Copied {yaml_count} EsBBQ YAML files from local repo.\")\n",
        "else:\n",
        "    print(f\"‚úÖ Downloaded {yaml_count} EsBBQ YAML files from GitHub.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SIMPLE INSTALLATION OF EsBBQ (files already cleaned in the repo)\n",
        "import os\n",
        "import shutil\n",
        "import lm_eval\n",
        "\n",
        "print(f\"{'='*70}\")\n",
        "print(\"üì¶ INSTALLING EsBBQ TASKS\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "# 1. Locate directories\n",
        "lib_path = os.path.dirname(lm_eval.__file__)\n",
        "target_dir = os.path.join(lib_path, \"tasks\", \"esbbq\")\n",
        "\n",
        "# 2. Clean and recreate directory\n",
        "if os.path.exists(target_dir):\n",
        "    shutil.rmtree(target_dir)\n",
        "os.makedirs(target_dir, exist_ok=True)\n",
        "print(f\"üìç TASKS DIRECTORY: {target_dir}\\n\")\n",
        "\n",
        "# 3. Copy all YAMLs and Python (.py) files\n",
        "files_to_copy = [f for f in os.listdir('custom_tasks/esbbq') if f.endswith('.yaml') or f.endswith('.py')]\n",
        "\n",
        "for file_name in files_to_copy:\n",
        "    src = os.path.join('custom_tasks/esbbq', file_name)\n",
        "    dst = os.path.join(target_dir, file_name)\n",
        "    shutil.copy(src, dst)\n",
        "    print(f\"   ‚úÖ {file_name}\")\n",
        "\n",
        "print(f\"\\nüöÄ OK! {len(files_to_copy)} EsBBQ files installed.\")"
      ],
      "metadata": {
        "id": "XFuUtNZjZyRJ",
        "outputId": "ad002366-23b5-4376-981b-968746c17a35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "üì¶ INSTALLING EsBBQ TASKS\n",
            "======================================================================\n",
            "üìç TASKS DIRECTORY: /usr/local/lib/python3.12/dist-packages/lm_eval/tasks/esbbq\n",
            "\n",
            "   ‚úÖ esbbq_utils.py\n",
            "   ‚úÖ esbbq_religion.yaml\n",
            "   ‚úÖ esbbq_lgbtqia.yaml\n",
            "   ‚úÖ esbbq_raceethnicity.yaml\n",
            "   ‚úÖ esbbq_ses.yaml\n",
            "   ‚úÖ esbbq_disabilitystatus.yaml\n",
            "   ‚úÖ esbbq_physicalappearance.yaml\n",
            "   ‚úÖ esbbq_nationality.yaml\n",
            "   ‚úÖ esbbq_age.yaml\n",
            "   ‚úÖ esbbq_spanishregion.yaml\n",
            "   ‚úÖ esbbq_gender.yaml\n",
            "\n",
            "üöÄ OK! 11 EsBBQ files installed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSOqtWXbhrRf"
      },
      "source": [
        "# 2. Helper Functions\n",
        "\n",
        "Utility functions for automatic checkpoint path generation and model size detection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "helper_functions",
        "outputId": "16214766-6a46-40bd-9cbf-c8b7985be7ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing helper functions:\n",
            "----------------------------------------------------------------------\n",
            "BSC-LT/salamandra-2b                               ‚Üí 2b\n",
            "meta-llama/Llama-3.2-1B                            ‚Üí 1b\n",
            "meta-llama/Llama-3.2-3B                            ‚Üí 3b\n",
            "----------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import os\n",
        "\n",
        "def get_model_size(model_name: str) -> str:\n",
        "    \"\"\"Extract model size identifier from HuggingFace model name.\n",
        "\n",
        "    Examples:\n",
        "        \"meta-llama/Llama-3.2-1B\" ‚Üí \"1b\"\n",
        "        \"meta-llama/Llama-3.2-3B-Instruct\" ‚Üí \"3b_instruct\"\n",
        "        \"BSC-LT/salamandra-2b\" ‚Üí \"2b\"\n",
        "    \"\"\"\n",
        "    match = re.search(r'(\\d+\\.?\\d*)[Bb]', model_name)\n",
        "    if not match:\n",
        "        return \"unknown\"\n",
        "\n",
        "    size = match.group(1).replace('.', '_') + \"b\"\n",
        "    if \"instruct\" in model_name.lower():\n",
        "        size += \"_instruct\"\n",
        "\n",
        "    return size.lower()\n",
        "\n",
        "def get_checkpoint_path(model_name: str, base_dir: str) -> str:\n",
        "    \"\"\"Generate checkpoint path with size-based subdirectory.\n",
        "\n",
        "    Args:\n",
        "        model_name: Full HuggingFace model identifier\n",
        "        base_dir: Base directory for checkpoints\n",
        "\n",
        "    Returns:\n",
        "        Full path to checkpoint file\n",
        "    \"\"\"\n",
        "    model_size = get_model_size(model_name)\n",
        "    safe_name = model_name.replace('/', '_').replace('-', '_').lower()\n",
        "    checkpoint_dir = os.path.join(base_dir, model_size)\n",
        "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "    return os.path.join(checkpoint_dir, f\"{safe_name}.json\")\n",
        "\n",
        "# Test with example models\n",
        "print(\"Testing helper functions:\")\n",
        "print(\"-\" * 70)\n",
        "test_models = [\n",
        "    \"BSC-LT/salamandra-2b\",\n",
        "    \"meta-llama/Llama-3.2-1B\",\n",
        "    \"meta-llama/Llama-3.2-3B\"\n",
        "]\n",
        "for model_id in test_models:\n",
        "    size = get_model_size(model_id)\n",
        "    print(f\"{model_id:<50} ‚Üí {size}\")\n",
        "print(\"-\" * 70)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "# Borrar cach√© de Datasets de Hugging Face (Aqu√≠ est√° el veneno)\n",
        "paths_to_clean = [\n",
        "    \"/root/.cache/huggingface/datasets\",\n",
        "    \"/root/.cache/huggingface/modules\",\n",
        "    os.path.expanduser(\"~/.cache/huggingface/datasets\")\n",
        "]\n",
        "\n",
        "print(\"üßπ Iniciando limpieza profunda de cach√© de Datasets...\")\n",
        "\n",
        "for p in paths_to_clean:\n",
        "    if os.path.exists(p):\n",
        "        try:\n",
        "            shutil.rmtree(p)\n",
        "            print(f\"‚úÖ Eliminado: {p}\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è No se pudo borrar {p}: {e}\")\n",
        "    else:\n",
        "        print(f\"‚ÑπÔ∏è No exist√≠a: {p}\")\n",
        "\n",
        "print(\"\\nüöÄ Cach√© limpia. La pr√≥xima ejecuci√≥n descargar√° los datos frescos y correctos.\")"
      ],
      "metadata": {
        "id": "xMl1lvSHZvIw",
        "outputId": "469bef13-5267-4689-9966-3161eb738000",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üßπ Iniciando limpieza profunda de cach√© de Datasets...\n",
            "‚úÖ Eliminado: /root/.cache/huggingface/datasets\n",
            "‚ÑπÔ∏è No exist√≠a: /root/.cache/huggingface/modules\n",
            "‚ÑπÔ∏è No exist√≠a: /root/.cache/huggingface/datasets\n",
            "\n",
            "üöÄ Cach√© limpia. La pr√≥xima ejecuci√≥n descargar√° los datos frescos y correctos.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goJTl4XJQjL6"
      },
      "source": [
        "# 3. Configuration & Evaluation Plan (MBBQ/EsBBQ)\n",
        "\n",
        "Configure paths, select EsBBQ tasks, and list the models we will evaluate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "EG53MfrJQjL6",
        "outputId": "ce1642aa-8315-4ea3-9315-28a4561d9397",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "üìä EVALUATION PLAN: MBBQ (EsBBQ) - Spanish Bias Benchmark\n",
            "======================================================================\n",
            "Checkpoints: /content/drive/MyDrive/fair_pruning/checkpoints_mbbq\n",
            "Results: /content/drive/MyDrive/fair_pruning/results\n",
            "Tasks: ['esbbq_age', 'esbbq_disabilitystatus', 'esbbq_gender', 'esbbq_lgbtqia', 'esbbq_nationality', 'esbbq_physicalappearance', 'esbbq_raceethnicity', 'esbbq_religion', 'esbbq_ses', 'esbbq_spanishregion']\n",
            "Limit per dataset: 100 (quick test mode)\n",
            "Models:\n",
            " - BSC-LT/salamandra-2b\n",
            " - meta-llama/Llama-3.2-1B\n",
            " - meta-llama/Llama-3.2-3B\n",
            "======================================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import json\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "import logging\n",
        "import os\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from IPython.display import display\n",
        "from utils import (\n",
        "    EXPERIMENT_CONFIG,\n",
        "    run_robust_evaluation,\n",
        "    load_or_create_model,\n",
        "    clear_gpu_cache,\n",
        "    format_results_table,\n",
        "    get_model_stats,\n",
        " )\n",
        "\n",
        "# Paths (Drive recommended in Colab)\n",
        "CHECKPOINT_BASE_DIR = \"/content/drive/MyDrive/fair_pruning/checkpoints_mbbq\"\n",
        "RESULTS_DIR = \"/content/drive/MyDrive/fair_pruning/results\"\n",
        "Path(CHECKPOINT_BASE_DIR).mkdir(parents=True, exist_ok=True)\n",
        "Path(RESULTS_DIR).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# EsBBQ (MBBQ) task list - all categories in one group (0-shot)\n",
        "# Using task group name that encompasses all EsBBQ subtasks\n",
        "MBBQ_TASKS = [\n",
        "    {\"name\": \"esbbq_age\", \"num_fewshot\": 0},\n",
        "    {\"name\": \"esbbq_disabilitystatus\", \"num_fewshot\": 0},\n",
        "    {\"name\": \"esbbq_gender\", \"num_fewshot\": 0},\n",
        "    {\"name\": \"esbbq_lgbtqia\", \"num_fewshot\": 0},\n",
        "    {\"name\": \"esbbq_nationality\", \"num_fewshot\": 0},\n",
        "    {\"name\": \"esbbq_physicalappearance\", \"num_fewshot\": 0},\n",
        "    {\"name\": \"esbbq_raceethnicity\", \"num_fewshot\": 0},\n",
        "    {\"name\": \"esbbq_religion\", \"num_fewshot\": 0},\n",
        "    {\"name\": \"esbbq_ses\", \"num_fewshot\": 0},\n",
        "    {\"name\": \"esbbq_spanishregion\", \"num_fewshot\": 0}\n",
        "]\n",
        "\n",
        "# De-duplicate models from EXPERIMENT_CONFIG\n",
        "unique_models = list(dict.fromkeys([cfg[\"base_model\"] for cfg in EXPERIMENT_CONFIG]))\n",
        "\n",
        "logging.getLogger(\"lm_eval\").setLevel(logging.INFO)\n",
        "\n",
        "print(f\"{'='*70}\")\n",
        "print(\"üìä EVALUATION PLAN: MBBQ (EsBBQ) - Spanish Bias Benchmark\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"Checkpoints: {CHECKPOINT_BASE_DIR}\")\n",
        "print(f\"Results: {RESULTS_DIR}\")\n",
        "print(f\"Tasks: {[task['name'] for task in MBBQ_TASKS]}\")\n",
        "print(f\"Limit per dataset: 100 (quick test mode)\")\n",
        "print(\"Models:\")\n",
        "for m in unique_models:\n",
        "    print(f\" - {m}\")\n",
        "print(f\"{'='*70}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYSCTWcyQjL6"
      },
      "source": [
        "# 4. Run MBBQ Evaluation\n",
        "\n",
        "Evaluate each base model on EsBBQ tasks with checkpoint/resume and raw result saving."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sx4LW8uCQjL6"
      },
      "outputs": [],
      "source": [
        "print(f\"\\n{'='*70}\")\n",
        "print(\"üöÄ STARTING MBBQ (EsBBQ) EVALUATION (Hugging Face Native Loading)\")\n",
        "print(f\"{'='*70}\\n\")\n",
        "\n",
        "all_model_results = {}\n",
        "\n",
        "# Pre-check simple para asegurar que datasets respira\n",
        "try:\n",
        "    from datasets import load_dataset\n",
        "    # Usamos una carga dummy r√°pida para asegurar que la librer√≠a no explota\n",
        "    print(\"üîç Verificando salud de la librer√≠a datasets...\")\n",
        "    # No usamos trust_remote_code=True aqu√≠ para evitar el warning de Belebele,\n",
        "    # simplemente comprobamos que podemos importar y cargar algo b√°sico.\n",
        "    print(\"‚úÖ Librer√≠a datasets operativa.\")\n",
        "except Exception as e_ds:\n",
        "    print(f\"‚ö†Ô∏è Alerta en pre-check (no bloqueante): {e_ds}\")\n",
        "\n",
        "\n",
        "for idx, model_id in enumerate(unique_models, 1):\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"üìä MODEL {idx}/{len(unique_models)}: {model_id}\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "    try:\n",
        "        # Generate checkpoint path\n",
        "        checkpoint_path = get_checkpoint_path(model_id, CHECKPOINT_BASE_DIR)\n",
        "\n",
        "        # 1. Definir directorios ANTES de usarlos (Correcci√≥n del NameError)\n",
        "        raw_results_dir = os.path.join(\n",
        "            os.path.dirname(checkpoint_path),\n",
        "            \"results\", \"lm_evals\"\n",
        "        )\n",
        "        os.makedirs(raw_results_dir, exist_ok=True)\n",
        "\n",
        "        # 2. Cargar Modelo\n",
        "        print(f\"üì• Loading directly from Hugging Face Hub...\")\n",
        "        model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_id,\n",
        "            torch_dtype=torch.bfloat16,\n",
        "            device_map=\"auto\"\n",
        "        )\n",
        "\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "        if tokenizer.pad_token is None:\n",
        "            tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "        print(\"‚úÖ Model loaded successfully (Native HF)\")\n",
        "\n",
        "        # Show statistics\n",
        "        stats = get_model_stats(model)\n",
        "        print(f\"üìà Params: {stats['total_parameters']:,} | Size: {stats['size_gb']:.2f} GB\")\n",
        "        print(f\"üìÅ Checkpoint: {checkpoint_path}\\n\")\n",
        "\n",
        "        # --- üïµÔ∏è DEBUGGING TRACES START ---\n",
        "        print(f\"\\n{'='*20} üïµÔ∏è DEBUGGING TRACES: {model_id} {'='*20}\")\n",
        "\n",
        "        # Verificar Identidad\n",
        "        print(f\"üÜî Object Memory ID: {id(model)}\")\n",
        "\n",
        "        # Verificar Vocabulario (Prueba definitiva de que es el modelo correcto)\n",
        "        test_word = \"Inteligencia Artificial\"\n",
        "        encoded_ids = tokenizer.encode(test_word)\n",
        "        print(f\"üî§ Tokenizer Check ('{test_word}'): {encoded_ids}\")\n",
        "        print(f\"üìè Vocab Size: {tokenizer.vocab_size}\")\n",
        "        if \"salamandra\" in model_id.lower() and tokenizer.vocab_size < 200000:\n",
        "            print(\"‚ö†Ô∏è ADVERTENCIA: Salamandra deber√≠a tener vocab > 200k. Revisa el tokenizer.\")\n",
        "\n",
        "        # Verificar si ya existen resultados previos\n",
        "        # Ahora raw_results_dir S√ç est√° definido\n",
        "        test_file = os.path.join(raw_results_dir, f\"{model_id.replace('/', '_')}_esbbq_age.json\")\n",
        "        if os.path.exists(test_file):\n",
        "            import time\n",
        "            mod_time = time.ctime(os.path.getmtime(test_file))\n",
        "            print(f\"üìÅ Fichero previo detectado: {test_file}\")\n",
        "            print(f\"   üïí Fecha: {mod_time} (Deber√≠a actualizarse al finalizar)\")\n",
        "        else:\n",
        "            print(f\"üìÅ Fichero nuevo. Se crear√° en: {raw_results_dir}\")\n",
        "\n",
        "        print(f\"{'='*60}\\n\")\n",
        "        # --- üïµÔ∏è DEBUGGING TRACES END ---\n",
        "\n",
        "        # 3. Ejecutar Evaluaci√≥n\n",
        "        from utils import model_evaluation\n",
        "\n",
        "        print(f\"üìä Running evaluation with limit=100 per task...\")\n",
        "        print(f\"üíæ Raw results will be saved to: {raw_results_dir}\\n\")\n",
        "\n",
        "        results = model_evaluation(\n",
        "            model_obj=model,\n",
        "            tokenizer=tokenizer,\n",
        "            tasks=MBBQ_TASKS,\n",
        "            limit=None,\n",
        "            save_raw_results=True,\n",
        "            raw_results_dir=raw_results_dir\n",
        "        )\n",
        "\n",
        "        # Save results to checkpoint format\n",
        "        checkpoint_data = {\n",
        "            \"metadata\": {\n",
        "                \"model_name\": model_id,\n",
        "                \"started_at\": datetime.now().isoformat(),\n",
        "                \"completed\": True,\n",
        "                \"completed_at\": datetime.now().isoformat()\n",
        "            },\n",
        "            \"results\": results,\n",
        "            \"pending_tasks\": [],\n",
        "            \"failed_tasks\": []\n",
        "        }\n",
        "\n",
        "        with open(checkpoint_path, 'w') as f:\n",
        "            json.dump(checkpoint_data, f, indent=2)\n",
        "\n",
        "        all_model_results[model_id] = results\n",
        "        print(f\"\\n‚úÖ Completed: {model_id}\")\n",
        "        print(\"Results Preview (first few tasks):\")\n",
        "        preview_results = {k: v for i, (k, v) in enumerate(results.items()) if i < 3}\n",
        "        print(format_results_table(preview_results))\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå ERROR evaluating {model_id}: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        if 'model' in locals(): del model\n",
        "        if 'tokenizer' in locals(): del tokenizer\n",
        "        clear_gpu_cache()\n",
        "        continue\n",
        "\n",
        "    # Memory cleanup\n",
        "    del model\n",
        "    del tokenizer\n",
        "    clear_gpu_cache()\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"‚úÖ MBBQ EVALUATION COMPLETE: {len(all_model_results)}/{len(unique_models)} models\")\n",
        "print(f\"{'='*70}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R20JPHfQQjL7"
      },
      "source": [
        "# 5. Consolidate MBBQ Results\n",
        "\n",
        "Load checkpoint files, flatten metrics, and export combined MBBQ results in CSV/JSON format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "5R9TwH-iQjL7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 938
        },
        "outputId": "6588766c-1012-4473-ba94-6b8659422b48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            " CONSOLIDATING MBBQ RESULTS\n",
            "======================================================================\n",
            "\n",
            "Total checkpoint JSONs found: 33\n",
            "\n",
            "üìä Consolidated 30 task results from 3 models\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                  model model_size                      task  \\\n",
              "0  BSC-LT/salamandra-2b         2b                 esbbq_age   \n",
              "1  BSC-LT/salamandra-2b         2b    esbbq_disabilitystatus   \n",
              "2  BSC-LT/salamandra-2b         2b              esbbq_gender   \n",
              "3  BSC-LT/salamandra-2b         2b             esbbq_lgbtqia   \n",
              "4  BSC-LT/salamandra-2b         2b         esbbq_nationality   \n",
              "5  BSC-LT/salamandra-2b         2b  esbbq_physicalappearance   \n",
              "6  BSC-LT/salamandra-2b         2b       esbbq_raceethnicity   \n",
              "7  BSC-LT/salamandra-2b         2b            esbbq_religion   \n",
              "8  BSC-LT/salamandra-2b         2b                 esbbq_ses   \n",
              "9  BSC-LT/salamandra-2b         2b       esbbq_spanishregion   \n",
              "\n",
              "                      alias     acc acc_stderr acc_norm acc_norm_stderr  \\\n",
              "0                 esbbq_age  0.3614     0.0075   0.3614          0.0075   \n",
              "1    esbbq_disabilitystatus  0.4520     0.0094   0.4520          0.0094   \n",
              "2              esbbq_gender  0.3609     0.0069   0.3609          0.0069   \n",
              "3             esbbq_lgbtqia  0.4220     0.0110   0.4220          0.0110   \n",
              "4         esbbq_nationality  0.4167     0.0220   0.4167          0.0220   \n",
              "5  esbbq_physicalappearance  0.5346     0.0084   0.5346          0.0084   \n",
              "6       esbbq_raceethnicity  0.3689     0.0079   0.3689          0.0079   \n",
              "7            esbbq_religion  0.4414     0.0195   0.4414          0.0195   \n",
              "8                 esbbq_ses  0.4436     0.0077   0.4436          0.0077   \n",
              "9       esbbq_spanishregion  0.3968     0.0156   0.3968          0.0156   \n",
              "\n",
              "  acc_ambig acc_ambig_stderr acc_disambig acc_disambig_stderr  \\\n",
              "0    0.0759              N/A       0.4942                 N/A   \n",
              "1    0.3308              N/A       0.5110                 N/A   \n",
              "2    0.0033              N/A       0.5225                 N/A   \n",
              "3    0.3455              N/A       0.4529                 N/A   \n",
              "4    0.1726              N/A       0.5387                 N/A   \n",
              "5    0.6148              N/A       0.4945                 N/A   \n",
              "6    0.0871              N/A       0.5080                 N/A   \n",
              "7    0.3009              N/A       0.5116                 N/A   \n",
              "8    0.3855              N/A       0.4720                 N/A   \n",
              "9    0.1944              N/A       0.4955                 N/A   \n",
              "\n",
              "  bias_score_ambig bias_score_ambig_stderr bias_score_disambig  \\\n",
              "0           0.0093                     N/A              0.0605   \n",
              "1           0.0248                     N/A              0.0200   \n",
              "2          -0.0007                     N/A              0.0030   \n",
              "3           0.0087                     N/A              0.0154   \n",
              "4           0.0417                     N/A             -0.0060   \n",
              "5           0.0077                     N/A              0.0808   \n",
              "6           0.0269                     N/A              0.0000   \n",
              "7          -0.0972                     N/A             -0.0694   \n",
              "8           0.0435                     N/A              0.0504   \n",
              "9           0.0154                     N/A             -0.0090   \n",
              "\n",
              "  bias_score_disambig_stderr  \n",
              "0                        N/A  \n",
              "1                        N/A  \n",
              "2                        N/A  \n",
              "3                        N/A  \n",
              "4                        N/A  \n",
              "5                        N/A  \n",
              "6                        N/A  \n",
              "7                        N/A  \n",
              "8                        N/A  \n",
              "9                        N/A  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6c44ee1f-ce67-4e5c-99d6-f3e0f2c8dc4b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>model_size</th>\n",
              "      <th>task</th>\n",
              "      <th>alias</th>\n",
              "      <th>acc</th>\n",
              "      <th>acc_stderr</th>\n",
              "      <th>acc_norm</th>\n",
              "      <th>acc_norm_stderr</th>\n",
              "      <th>acc_ambig</th>\n",
              "      <th>acc_ambig_stderr</th>\n",
              "      <th>acc_disambig</th>\n",
              "      <th>acc_disambig_stderr</th>\n",
              "      <th>bias_score_ambig</th>\n",
              "      <th>bias_score_ambig_stderr</th>\n",
              "      <th>bias_score_disambig</th>\n",
              "      <th>bias_score_disambig_stderr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BSC-LT/salamandra-2b</td>\n",
              "      <td>2b</td>\n",
              "      <td>esbbq_age</td>\n",
              "      <td>esbbq_age</td>\n",
              "      <td>0.3614</td>\n",
              "      <td>0.0075</td>\n",
              "      <td>0.3614</td>\n",
              "      <td>0.0075</td>\n",
              "      <td>0.0759</td>\n",
              "      <td>N/A</td>\n",
              "      <td>0.4942</td>\n",
              "      <td>N/A</td>\n",
              "      <td>0.0093</td>\n",
              "      <td>N/A</td>\n",
              "      <td>0.0605</td>\n",
              "      <td>N/A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BSC-LT/salamandra-2b</td>\n",
              "      <td>2b</td>\n",
              "      <td>esbbq_disabilitystatus</td>\n",
              "      <td>esbbq_disabilitystatus</td>\n",
              "      <td>0.4520</td>\n",
              "      <td>0.0094</td>\n",
              "      <td>0.4520</td>\n",
              "      <td>0.0094</td>\n",
              "      <td>0.3308</td>\n",
              "      <td>N/A</td>\n",
              "      <td>0.5110</td>\n",
              "      <td>N/A</td>\n",
              "      <td>0.0248</td>\n",
              "      <td>N/A</td>\n",
              "      <td>0.0200</td>\n",
              "      <td>N/A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>BSC-LT/salamandra-2b</td>\n",
              "      <td>2b</td>\n",
              "      <td>esbbq_gender</td>\n",
              "      <td>esbbq_gender</td>\n",
              "      <td>0.3609</td>\n",
              "      <td>0.0069</td>\n",
              "      <td>0.3609</td>\n",
              "      <td>0.0069</td>\n",
              "      <td>0.0033</td>\n",
              "      <td>N/A</td>\n",
              "      <td>0.5225</td>\n",
              "      <td>N/A</td>\n",
              "      <td>-0.0007</td>\n",
              "      <td>N/A</td>\n",
              "      <td>0.0030</td>\n",
              "      <td>N/A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>BSC-LT/salamandra-2b</td>\n",
              "      <td>2b</td>\n",
              "      <td>esbbq_lgbtqia</td>\n",
              "      <td>esbbq_lgbtqia</td>\n",
              "      <td>0.4220</td>\n",
              "      <td>0.0110</td>\n",
              "      <td>0.4220</td>\n",
              "      <td>0.0110</td>\n",
              "      <td>0.3455</td>\n",
              "      <td>N/A</td>\n",
              "      <td>0.4529</td>\n",
              "      <td>N/A</td>\n",
              "      <td>0.0087</td>\n",
              "      <td>N/A</td>\n",
              "      <td>0.0154</td>\n",
              "      <td>N/A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>BSC-LT/salamandra-2b</td>\n",
              "      <td>2b</td>\n",
              "      <td>esbbq_nationality</td>\n",
              "      <td>esbbq_nationality</td>\n",
              "      <td>0.4167</td>\n",
              "      <td>0.0220</td>\n",
              "      <td>0.4167</td>\n",
              "      <td>0.0220</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>N/A</td>\n",
              "      <td>0.5387</td>\n",
              "      <td>N/A</td>\n",
              "      <td>0.0417</td>\n",
              "      <td>N/A</td>\n",
              "      <td>-0.0060</td>\n",
              "      <td>N/A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>BSC-LT/salamandra-2b</td>\n",
              "      <td>2b</td>\n",
              "      <td>esbbq_physicalappearance</td>\n",
              "      <td>esbbq_physicalappearance</td>\n",
              "      <td>0.5346</td>\n",
              "      <td>0.0084</td>\n",
              "      <td>0.5346</td>\n",
              "      <td>0.0084</td>\n",
              "      <td>0.6148</td>\n",
              "      <td>N/A</td>\n",
              "      <td>0.4945</td>\n",
              "      <td>N/A</td>\n",
              "      <td>0.0077</td>\n",
              "      <td>N/A</td>\n",
              "      <td>0.0808</td>\n",
              "      <td>N/A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>BSC-LT/salamandra-2b</td>\n",
              "      <td>2b</td>\n",
              "      <td>esbbq_raceethnicity</td>\n",
              "      <td>esbbq_raceethnicity</td>\n",
              "      <td>0.3689</td>\n",
              "      <td>0.0079</td>\n",
              "      <td>0.3689</td>\n",
              "      <td>0.0079</td>\n",
              "      <td>0.0871</td>\n",
              "      <td>N/A</td>\n",
              "      <td>0.5080</td>\n",
              "      <td>N/A</td>\n",
              "      <td>0.0269</td>\n",
              "      <td>N/A</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>N/A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>BSC-LT/salamandra-2b</td>\n",
              "      <td>2b</td>\n",
              "      <td>esbbq_religion</td>\n",
              "      <td>esbbq_religion</td>\n",
              "      <td>0.4414</td>\n",
              "      <td>0.0195</td>\n",
              "      <td>0.4414</td>\n",
              "      <td>0.0195</td>\n",
              "      <td>0.3009</td>\n",
              "      <td>N/A</td>\n",
              "      <td>0.5116</td>\n",
              "      <td>N/A</td>\n",
              "      <td>-0.0972</td>\n",
              "      <td>N/A</td>\n",
              "      <td>-0.0694</td>\n",
              "      <td>N/A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>BSC-LT/salamandra-2b</td>\n",
              "      <td>2b</td>\n",
              "      <td>esbbq_ses</td>\n",
              "      <td>esbbq_ses</td>\n",
              "      <td>0.4436</td>\n",
              "      <td>0.0077</td>\n",
              "      <td>0.4436</td>\n",
              "      <td>0.0077</td>\n",
              "      <td>0.3855</td>\n",
              "      <td>N/A</td>\n",
              "      <td>0.4720</td>\n",
              "      <td>N/A</td>\n",
              "      <td>0.0435</td>\n",
              "      <td>N/A</td>\n",
              "      <td>0.0504</td>\n",
              "      <td>N/A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>BSC-LT/salamandra-2b</td>\n",
              "      <td>2b</td>\n",
              "      <td>esbbq_spanishregion</td>\n",
              "      <td>esbbq_spanishregion</td>\n",
              "      <td>0.3968</td>\n",
              "      <td>0.0156</td>\n",
              "      <td>0.3968</td>\n",
              "      <td>0.0156</td>\n",
              "      <td>0.1944</td>\n",
              "      <td>N/A</td>\n",
              "      <td>0.4955</td>\n",
              "      <td>N/A</td>\n",
              "      <td>0.0154</td>\n",
              "      <td>N/A</td>\n",
              "      <td>-0.0090</td>\n",
              "      <td>N/A</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6c44ee1f-ce67-4e5c-99d6-f3e0f2c8dc4b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6c44ee1f-ce67-4e5c-99d6-f3e0f2c8dc4b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6c44ee1f-ce67-4e5c-99d6-f3e0f2c8dc4b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    print(\\\"\\u26a0\\ufe0f No MBBQ results found to consolidate\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"BSC-LT/salamandra-2b\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model_size\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"2b\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"task\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"esbbq_ses\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"alias\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"esbbq_ses\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"acc\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"0.4436\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"acc_stderr\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"0.0077\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"acc_norm\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"0.4436\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"acc_norm_stderr\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"0.0077\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"acc_ambig\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"0.3855\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"acc_ambig_stderr\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"N/A\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"acc_disambig\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"0.4720\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"acc_disambig_stderr\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"N/A\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bias_score_ambig\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"0.0435\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bias_score_ambig_stderr\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"N/A\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bias_score_disambig\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"0.0504\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bias_score_disambig_stderr\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"N/A\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üíæ MBBQ results saved:\n",
            "   /content/drive/MyDrive/fair_pruning/results/base_models_mbbq_results_20260220_202938.csv\n",
            "   /content/drive/MyDrive/fair_pruning/results/base_models_mbbq_results_latest.csv\n",
            "   /content/drive/MyDrive/fair_pruning/results/base_models_mbbq_results_20260220_202938.json\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "\n",
        "def flatten_metrics(metrics, prefix=''):\n",
        "    \"\"\"Recursively flatten nested metric dictionaries.\"\"\"\n",
        "    flat = {}\n",
        "    for k, v in metrics.items():\n",
        "        if isinstance(v, dict):\n",
        "            flat.update(flatten_metrics(v, prefix=f\"{prefix}{k}_\"))\n",
        "        else:\n",
        "            flat[f\"{prefix}{k}\"] = v\n",
        "    return flat\n",
        "\n",
        "print(f\"{'='*70}\")\n",
        "print(\" CONSOLIDATING MBBQ RESULTS\")\n",
        "print(f\"{'='*70}\\n\")\n",
        "\n",
        "checkpoint_files = glob.glob(f\"{CHECKPOINT_BASE_DIR}/**/*.json\", recursive=True)\n",
        "print(f\"Total checkpoint JSONs found: {len(checkpoint_files)}\")\n",
        "\n",
        "consolidated_data = []\n",
        "\n",
        "for json_path in sorted(checkpoint_files):\n",
        "    # Skip raw lm-eval dumps (only process model checkpoints)\n",
        "    if \"lm_evals\" in json_path:\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        with open(json_path, \"r\") as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        metadata = data.get(\"metadata\", {})\n",
        "        model_name = metadata.get(\"model_name\", \"Unknown\")\n",
        "\n",
        "        # Extract model size\n",
        "        model_size = get_model_size(model_name)\n",
        "\n",
        "        results = data.get(\"results\", {})\n",
        "        if not results:\n",
        "            continue\n",
        "\n",
        "        for task_name, metrics in results.items():\n",
        "            row = {\n",
        "                \"model\": model_name,\n",
        "                \"model_size\": model_size,\n",
        "                \"task\": task_name,\n",
        "            }\n",
        "            row.update(flatten_metrics(metrics))\n",
        "            consolidated_data.append(row)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"   ‚ö†Ô∏è Error reading {json_path}: {e}\")\n",
        "\n",
        "if consolidated_data:\n",
        "    df = pd.DataFrame(consolidated_data)\n",
        "    df = df.sort_values(by=[\"model\", \"task\"]).reset_index(drop=True)\n",
        "\n",
        "    print(f\"\\nüìä Consolidated {len(df)} task results from {df['model'].nunique()} models\")\n",
        "    display(df.head(10))\n",
        "\n",
        "    # Save timestamped and latest versions\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    csv_path = f\"{RESULTS_DIR}/base_models_mbbq_results_{timestamp}.csv\"\n",
        "    latest_csv = f\"{RESULTS_DIR}/base_models_mbbq_results_latest.csv\"\n",
        "    json_path = f\"{RESULTS_DIR}/base_models_mbbq_results_{timestamp}.json\"\n",
        "\n",
        "    df.to_csv(csv_path, index=False)\n",
        "    df.to_csv(latest_csv, index=False)\n",
        "    df.to_json(json_path, orient=\"records\", indent=2)\n",
        "\n",
        "    print(\"\\nüíæ MBBQ results saved:\")\n",
        "    print(f\"   {csv_path}\")\n",
        "    print(f\"   {latest_csv}\")\n",
        "    print(f\"   {json_path}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No MBBQ results found to consolidate.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-EPjbK_QjL7"
      },
      "source": [
        "# 6. Summary Analysis\n",
        "\n",
        "Quick per-model accuracy summary for MBBQ and file inventory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "uDBqo_5iQjL7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f133dce-bdc7-4156-e188-b94cedeab593"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "üìà MBBQ SUMMARY\n",
            "======================================================================\n",
            "                  model model_size  avg_accuracy  tasks_completed  categories_evaluated\n",
            "   BSC-LT/salamandra-2b         2b        0.4198               10                    10\n",
            "meta-llama/Llama-3.2-1B         1b        0.4252               10                    10\n",
            "meta-llama/Llama-3.2-3B         3b        0.5322               10                    10\n",
            "\n",
            "üíæ Summary saved: /content/drive/MyDrive/fair_pruning/results/base_models_mbbq_summary_20260220_202939.csv\n",
            "\n",
            "======================================================================\n",
            "üìÅ GENERATED FILES\n",
            "======================================================================\n",
            "  ‚úÖ /content/drive/MyDrive/fair_pruning/results/base_models_mbbq_results_20260220_202938.csv\n",
            "  ‚úÖ /content/drive/MyDrive/fair_pruning/results/base_models_mbbq_results_latest.csv\n",
            "  ‚úÖ /content/drive/MyDrive/fair_pruning/results/base_models_mbbq_results_20260220_202938.json\n",
            "  ‚úÖ /content/drive/MyDrive/fair_pruning/results/base_models_mbbq_summary_20260220_202939.csv\n",
            "\n",
            "Checkpoints (first 10):\n",
            "  ‚úÖ /content/drive/MyDrive/fair_pruning/checkpoints_mbbq/1b/meta_llama_llama_3.2_1b.json\n",
            "  ‚úÖ /content/drive/MyDrive/fair_pruning/checkpoints_mbbq/2b/bsc_lt_salamandra_2b.json\n",
            "  ‚úÖ /content/drive/MyDrive/fair_pruning/checkpoints_mbbq/3b/meta_llama_llama_3.2_3b.json\n",
            "\n",
            "Raw LM-Eval dumps (first 10):\n",
            "  ‚úÖ /content/drive/MyDrive/fair_pruning/checkpoints_mbbq/1b/results/lm_evals/meta_llama_llama_3.2_1b_esbbq_age.json\n",
            "  ‚úÖ /content/drive/MyDrive/fair_pruning/checkpoints_mbbq/1b/results/lm_evals/meta_llama_llama_3.2_1b_esbbq_disabilitystatus.json\n",
            "  ‚úÖ /content/drive/MyDrive/fair_pruning/checkpoints_mbbq/1b/results/lm_evals/meta_llama_llama_3.2_1b_esbbq_gender.json\n",
            "  ‚úÖ /content/drive/MyDrive/fair_pruning/checkpoints_mbbq/1b/results/lm_evals/meta_llama_llama_3.2_1b_esbbq_lgbtqia.json\n",
            "  ‚úÖ /content/drive/MyDrive/fair_pruning/checkpoints_mbbq/1b/results/lm_evals/meta_llama_llama_3.2_1b_esbbq_nationality.json\n",
            "  ‚úÖ /content/drive/MyDrive/fair_pruning/checkpoints_mbbq/1b/results/lm_evals/meta_llama_llama_3.2_1b_esbbq_physicalappearance.json\n",
            "  ‚úÖ /content/drive/MyDrive/fair_pruning/checkpoints_mbbq/1b/results/lm_evals/meta_llama_llama_3.2_1b_esbbq_raceethnicity.json\n",
            "  ‚úÖ /content/drive/MyDrive/fair_pruning/checkpoints_mbbq/1b/results/lm_evals/meta_llama_llama_3.2_1b_esbbq_religion.json\n",
            "  ‚úÖ /content/drive/MyDrive/fair_pruning/checkpoints_mbbq/1b/results/lm_evals/meta_llama_llama_3.2_1b_esbbq_ses.json\n",
            "  ‚úÖ /content/drive/MyDrive/fair_pruning/checkpoints_mbbq/1b/results/lm_evals/meta_llama_llama_3.2_1b_esbbq_spanishregion.json\n",
            "  ... and 20 more\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# Generate summary statistics\n",
        "summary_df = None\n",
        "if 'df' in locals() and not df.empty:\n",
        "    summaries = []\n",
        "    for model_name, model_df in df.groupby('model'):\n",
        "        acc_series = pd.to_numeric(model_df.get('acc', model_df.get('accuracy')), errors='coerce').dropna()\n",
        "        summaries.append({\n",
        "            \"model\": model_name,\n",
        "            \"model_size\": model_df.get('model_size', pd.Series(['unknown'])).iloc[0],\n",
        "            \"avg_accuracy\": acc_series.mean() if len(acc_series) else None,\n",
        "            \"tasks_completed\": len(model_df),\n",
        "            \"categories_evaluated\": len(model_df['task'].unique())\n",
        "        })\n",
        "\n",
        "    summary_df = pd.DataFrame(summaries)\n",
        "    summary_df = summary_df.sort_values(\"model\").reset_index(drop=True)\n",
        "\n",
        "    print(f\"{'='*70}\")\n",
        "    print(\"üìà MBBQ SUMMARY\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(summary_df.to_string(index=False, float_format=\"%.4f\"))\n",
        "\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    summary_csv = f\"{RESULTS_DIR}/base_models_mbbq_summary_{timestamp}.csv\"\n",
        "    summary_df.to_csv(summary_csv, index=False)\n",
        "    print(f\"\\nüíæ Summary saved: {summary_csv}\\n\")\n",
        "else:\n",
        "    print(\"No consolidated data available for summary.\")\n",
        "\n",
        "# List all generated files\n",
        "print(f\"{'='*70}\")\n",
        "print(\"üìÅ GENERATED FILES\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "if 'csv_path' in locals() and os.path.exists(csv_path):\n",
        "    print(f\"  ‚úÖ {csv_path}\")\n",
        "if 'latest_csv' in locals() and os.path.exists(latest_csv):\n",
        "    print(f\"  ‚úÖ {latest_csv}\")\n",
        "if 'json_path' in locals() and os.path.exists(json_path):\n",
        "    print(f\"  ‚úÖ {json_path}\")\n",
        "if 'summary_csv' in locals() and os.path.exists(summary_csv):\n",
        "    print(f\"  ‚úÖ {summary_csv}\")\n",
        "\n",
        "print(\"\\nCheckpoints (first 10):\")\n",
        "if 'checkpoint_files' in locals():\n",
        "    model_checkpoints = [f for f in sorted(checkpoint_files) if \"lm_evals\" not in f]\n",
        "    for f in model_checkpoints[:10]:\n",
        "        print(f\"  ‚úÖ {f}\")\n",
        "    if len(model_checkpoints) > 10:\n",
        "        print(f\"  ... and {len(model_checkpoints) - 10} more\")\n",
        "\n",
        "print(\"\\nRaw LM-Eval dumps (first 10):\")\n",
        "if 'checkpoint_files' in locals():\n",
        "    raw_dumps = [f for f in sorted(checkpoint_files) if \"lm_evals\" in f]\n",
        "    for f in raw_dumps[:10]:\n",
        "        print(f\"  ‚úÖ {f}\")\n",
        "    if len(raw_dumps) > 10:\n",
        "        print(f\"  ... and {len(raw_dumps) - 10} more\")\n",
        "\n",
        "print(f\"{'='*70}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bias_analysis"
      },
      "source": [
        "# 7. Bias Analysis by Category\n",
        "\n",
        "Analyze bias metrics across EsBBQ categories for each model."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "\n",
        "if 'df' in locals() and not df.empty:\n",
        "    print(f\"{'='*70}\")\n",
        "    print(\"üìä BIAS ANALYSIS BY CATEGORY\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "\n",
        "    # --- CORRECCI√ìN CR√çTICA ---\n",
        "    # 1. Unificar nombres: Si existe 'acc' (BBQ) pero no 'accuracy', √∫salo.\n",
        "    # 2. Convertir a N√öMEROS: Forzamos la conversi√≥n de texto a float.\n",
        "    target_col = 'acc' if 'acc' in df.columns else 'accuracy'\n",
        "\n",
        "    # Creamos/Sobreescribimos la columna 'accuracy' asegurando que sea num√©rica\n",
        "    # errors='coerce' transformar√° cualquier valor no num√©rico en NaN (Not a Number) para no romper el c√≥digo\n",
        "    df['accuracy'] = pd.to_numeric(df[target_col], errors='coerce')\n",
        "    # ---------------------------\n",
        "\n",
        "    # Extract category from task name (e.g., esbbq_age -> age)\n",
        "    df['category'] = df['task'].astype(str).str.replace('esbbq_', '')\n",
        "\n",
        "    # Pivot table: models as rows, categories as columns\n",
        "    # Ahora que 'accuracy' es float, aggfunc='mean' funcionar√° correctamente\n",
        "    if 'accuracy' in df.columns:\n",
        "        pivot_df = df.pivot_table(\n",
        "            index='model',\n",
        "            columns='category',\n",
        "            values='accuracy',\n",
        "            aggfunc='mean'\n",
        "        )\n",
        "\n",
        "        print(\"\\nAccuracy by Category:\")\n",
        "        display(pivot_df)\n",
        "\n",
        "        # Save category breakdown\n",
        "        if 'RESULTS_DIR' in locals():\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            category_csv = f\"{RESULTS_DIR}/mbbq_category_breakdown_{timestamp}.csv\"\n",
        "            pivot_df.to_csv(category_csv)\n",
        "            print(f\"\\nüíæ Category breakdown saved: {category_csv}\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è Column 'accuracy' not found. Available columns:\", df.columns.tolist())\n",
        "\n",
        "    # Show bias score distribution if available\n",
        "    bias_cols = [col for col in df.columns if 'bias' in col.lower()]\n",
        "    if bias_cols:\n",
        "        print(\"\\nüìä Available bias metrics:\")\n",
        "        for col in bias_cols:\n",
        "            print(f\"   - {col}\")\n",
        "else:\n",
        "    print(\"No data available for category analysis.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "xevsDorT6JY_",
        "outputId": "671d3a5b-9a66-4511-9a8a-f77badad8e7b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "üìä BIAS ANALYSIS BY CATEGORY\n",
            "======================================================================\n",
            "\n",
            "\n",
            "Accuracy by Category:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "category                    age  disabilitystatus  gender  lgbtqia  \\\n",
              "model                                                                \n",
              "BSC-LT/salamandra-2b     0.3614             0.452  0.3609    0.422   \n",
              "meta-llama/Llama-3.2-1B  0.3387             0.453  0.3876    0.454   \n",
              "meta-llama/Llama-3.2-3B  0.4400             0.560  0.4729    0.533   \n",
              "\n",
              "category                 nationality  physicalappearance  raceethnicity  \\\n",
              "model                                                                     \n",
              "BSC-LT/salamandra-2b          0.4167              0.5346         0.3689   \n",
              "meta-llama/Llama-3.2-1B       0.4306              0.4858         0.3652   \n",
              "meta-llama/Llama-3.2-3B       0.5575              0.6040         0.5008   \n",
              "\n",
              "category                 religion     ses  spanishregion  \n",
              "model                                                     \n",
              "BSC-LT/salamandra-2b       0.4414  0.4436         0.3968  \n",
              "meta-llama/Llama-3.2-1B    0.4552  0.4346         0.4474  \n",
              "meta-llama/Llama-3.2-3B    0.5077  0.5592         0.5870  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b2e7ab36-4d30-4d40-b4f9-c0565a88859e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>category</th>\n",
              "      <th>age</th>\n",
              "      <th>disabilitystatus</th>\n",
              "      <th>gender</th>\n",
              "      <th>lgbtqia</th>\n",
              "      <th>nationality</th>\n",
              "      <th>physicalappearance</th>\n",
              "      <th>raceethnicity</th>\n",
              "      <th>religion</th>\n",
              "      <th>ses</th>\n",
              "      <th>spanishregion</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>model</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>BSC-LT/salamandra-2b</th>\n",
              "      <td>0.3614</td>\n",
              "      <td>0.452</td>\n",
              "      <td>0.3609</td>\n",
              "      <td>0.422</td>\n",
              "      <td>0.4167</td>\n",
              "      <td>0.5346</td>\n",
              "      <td>0.3689</td>\n",
              "      <td>0.4414</td>\n",
              "      <td>0.4436</td>\n",
              "      <td>0.3968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>meta-llama/Llama-3.2-1B</th>\n",
              "      <td>0.3387</td>\n",
              "      <td>0.453</td>\n",
              "      <td>0.3876</td>\n",
              "      <td>0.454</td>\n",
              "      <td>0.4306</td>\n",
              "      <td>0.4858</td>\n",
              "      <td>0.3652</td>\n",
              "      <td>0.4552</td>\n",
              "      <td>0.4346</td>\n",
              "      <td>0.4474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>meta-llama/Llama-3.2-3B</th>\n",
              "      <td>0.4400</td>\n",
              "      <td>0.560</td>\n",
              "      <td>0.4729</td>\n",
              "      <td>0.533</td>\n",
              "      <td>0.5575</td>\n",
              "      <td>0.6040</td>\n",
              "      <td>0.5008</td>\n",
              "      <td>0.5077</td>\n",
              "      <td>0.5592</td>\n",
              "      <td>0.5870</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b2e7ab36-4d30-4d40-b4f9-c0565a88859e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b2e7ab36-4d30-4d40-b4f9-c0565a88859e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b2e7ab36-4d30-4d40-b4f9-c0565a88859e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_94f9c070-c3fe-46b0-9ccb-fb0d4747201b\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('pivot_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_94f9c070-c3fe-46b0-9ccb-fb0d4747201b button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('pivot_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "pivot_df",
              "summary": "{\n  \"name\": \"pivot_df\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"BSC-LT/salamandra-2b\",\n          \"meta-llama/Llama-3.2-1B\",\n          \"meta-llama/Llama-3.2-3B\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05315847376790772,\n        \"min\": 0.3387,\n        \"max\": 0.44,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.3614,\n          0.3387,\n          0.44\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"disabilitystatus\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.062067167917775466,\n        \"min\": 0.452,\n        \"max\": 0.56,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.452,\n          0.453,\n          0.56\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gender\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.058499259254569475,\n        \"min\": 0.3609,\n        \"max\": 0.4729,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.3609,\n          0.3876,\n          0.4729\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lgbtqia\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05713434460404124,\n        \"min\": 0.422,\n        \"max\": 0.533,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.422,\n          0.454,\n          0.533\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nationality\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07759022704782692,\n        \"min\": 0.4167,\n        \"max\": 0.5575,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.4167,\n          0.4306,\n          0.5575\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"physicalappearance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05939842871097965,\n        \"min\": 0.4858,\n        \"max\": 0.604,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.5346,\n          0.4858,\n          0.604\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"raceethnicity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07724275586314444,\n        \"min\": 0.3652,\n        \"max\": 0.5008,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.3689,\n          0.3652,\n          0.5008\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"religion\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03498185243808568,\n        \"min\": 0.4414,\n        \"max\": 0.5077,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.4414,\n          0.4552,\n          0.5077\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ses\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06948563400684588,\n        \"min\": 0.4346,\n        \"max\": 0.5592,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.4436,\n          0.4346,\n          0.5592\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"spanishregion\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09850935657760297,\n        \"min\": 0.3968,\n        \"max\": 0.587,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.3968,\n          0.4474,\n          0.587\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üíæ Category breakdown saved: /content/drive/MyDrive/fair_pruning/results/mbbq_category_breakdown_20260220_202939.csv\n",
            "\n",
            "üìä Available bias metrics:\n",
            "   - bias_score_ambig\n",
            "   - bias_score_ambig_stderr\n",
            "   - bias_score_disambig\n",
            "   - bias_score_disambig_stderr\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Unf4RF81B5_h"
      },
      "execution_count": 24,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}